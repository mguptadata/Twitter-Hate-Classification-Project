{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "\n",
    "# NLTK/NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from nltk.collocations import *\n",
    "import gensim\n",
    "\n",
    "# Classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Sampling\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import sklearn.decomposition as decomposition\n",
    "\n",
    "#Visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "5      3            1                   2        0      1   \n",
       "6      3            0                   3        0      1   \n",
       "7      3            0                   3        0      1   \n",
       "8      3            0                   3        0      1   \n",
       "9      3            1                   2        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...  \n",
       "6  !!!!!!\"@__BrighterDays: I can not just sit up ...  \n",
       "7  !!!!&#8220;@selfiequeenbri: cause I'm tired of...  \n",
       "8  \" &amp; you might not get ya bitch back &amp; ...  \n",
       "9  \" @rhythmixx_ :hobbies include: fighting Maria...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/dataset2.csv')\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tidy_tweet'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tidy_tweet'] = df['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tidy_tweet']= df['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_hash_tweet']= df['tidy_tweet'].str.replace(\"#\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>[woman, shouldn, complain, about, cleaning, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>[dats, cold, tyga, cuffin, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>[Dawg, ever, fuck, bitch, start, confused, shit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>[look, like, tranny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                     tokenized_tweet  \n",
       "0  [woman, shouldn, complain, about, cleaning, yo...  \n",
       "1                  [dats, cold, tyga, cuffin, place]  \n",
       "2   [Dawg, ever, fuck, bitch, start, confused, shit]  \n",
       "3                               [look, like, tranny]  \n",
       "4  [shit, hear, about, might, true, might, faker,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweet'] = df['no_hash_tweet'].apply(lambda x: x.split())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>[woman, shouldn, complain, about, cleaning, yo...</td>\n",
       "      <td>[woman, shouldn, complain, about, clean, your,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>[dats, cold, tyga, cuffin, place]</td>\n",
       "      <td>[dat, cold, tyga, cuffin, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>[Dawg, ever, fuck, bitch, start, confused, shit]</td>\n",
       "      <td>[dawg, ever, fuck, bitch, start, confus, shit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>[look, like, tranny]</td>\n",
       "      <td>[look, like, tranni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0  [woman, shouldn, complain, about, cleaning, yo...   \n",
       "1                  [dats, cold, tyga, cuffin, place]   \n",
       "2   [Dawg, ever, fuck, bitch, start, confused, shit]   \n",
       "3                               [look, like, tranny]   \n",
       "4  [shit, hear, about, might, true, might, faker,...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  [woman, shouldn, complain, about, clean, your,...  \n",
       "1                   [dat, cold, tyga, cuffin, place]  \n",
       "2     [dawg, ever, fuck, bitch, start, confus, shit]  \n",
       "3                               [look, like, tranni]  \n",
       "4  [shit, hear, about, might, true, might, faker,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "df['stemmed_tokens'] = df.tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>[woman, shouldn, complain, about, cleaning, yo...</td>\n",
       "      <td>[woman, shouldn, complain, about, clean, your,...</td>\n",
       "      <td>[woman, shouldn, complain, about, cleaning, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>[dats, cold, tyga, cuffin, place]</td>\n",
       "      <td>[dat, cold, tyga, cuffin, place]</td>\n",
       "      <td>[dat, cold, tyga, cuffin, place]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>[Dawg, ever, fuck, bitch, start, confused, shit]</td>\n",
       "      <td>[dawg, ever, fuck, bitch, start, confus, shit]</td>\n",
       "      <td>[Dawg, ever, fuck, bitch, start, confused, shit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>[look, like, tranny]</td>\n",
       "      <td>[look, like, tranni]</td>\n",
       "      <td>[look, like, tranny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0  [woman, shouldn, complain, about, cleaning, yo...   \n",
       "1                  [dats, cold, tyga, cuffin, place]   \n",
       "2   [Dawg, ever, fuck, bitch, start, confused, shit]   \n",
       "3                               [look, like, tranny]   \n",
       "4  [shit, hear, about, might, true, might, faker,...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [woman, shouldn, complain, about, clean, your,...   \n",
       "1                   [dat, cold, tyga, cuffin, place]   \n",
       "2     [dawg, ever, fuck, bitch, start, confus, shit]   \n",
       "3                               [look, like, tranni]   \n",
       "4  [shit, hear, about, might, true, might, faker,...   \n",
       "\n",
       "                                   lemmatized_tokens  \n",
       "0  [woman, shouldn, complain, about, cleaning, yo...  \n",
       "1                   [dat, cold, tyga, cuffin, place]  \n",
       "2   [Dawg, ever, fuck, bitch, start, confused, shit]  \n",
       "3                               [look, like, tranny]  \n",
       "4  [shit, hear, about, might, true, might, faker,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_tokens'] = df.tokenized_tweet.apply(lambda x: [lemmatizer.lemmatize(i) for i in x]) # lemmatizing\n",
    "# [lemmatizer.lemmatize(word) for word in df.no_hash_tweet]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stemmed_tokens[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem_tweet'] = [lemmatizer.lemmatize(word) for word in df.no_hash_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem_tweet'] = [stemmer.stem(word) for word in df.no_hash_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>[woman, shouldn, complain, about, cleaning, yo...</td>\n",
       "      <td>[woman, shouldn, complain, about, clean, your,...</td>\n",
       "      <td>[woman, shouldn, complain, about, cleaning, yo...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "      <td>woman shouldn complain about cleaning your hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>[dats, cold, tyga, cuffin, place]</td>\n",
       "      <td>[dat, cold, tyga, cuffin, place]</td>\n",
       "      <td>[dat, cold, tyga, cuffin, place]</td>\n",
       "      <td>dats cold tyga cuffin place</td>\n",
       "      <td>dats cold tyga cuffin plac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>[Dawg, ever, fuck, bitch, start, confused, shit]</td>\n",
       "      <td>[dawg, ever, fuck, bitch, start, confus, shit]</td>\n",
       "      <td>[Dawg, ever, fuck, bitch, start, confused, shit]</td>\n",
       "      <td>Dawg ever fuck bitch start confused shit</td>\n",
       "      <td>dawg ever fuck bitch start confused shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>[look, like, tranny]</td>\n",
       "      <td>[look, like, tranni]</td>\n",
       "      <td>[look, like, tranny]</td>\n",
       "      <td>look like tranny</td>\n",
       "      <td>look like tranni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "      <td>[shit, hear, about, might, true, might, faker,...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "      <td>shit hear about might true might faker than bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0  [woman, shouldn, complain, about, cleaning, yo...   \n",
       "1                  [dats, cold, tyga, cuffin, place]   \n",
       "2   [Dawg, ever, fuck, bitch, start, confused, shit]   \n",
       "3                               [look, like, tranny]   \n",
       "4  [shit, hear, about, might, true, might, faker,...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [woman, shouldn, complain, about, clean, your,...   \n",
       "1                   [dat, cold, tyga, cuffin, place]   \n",
       "2     [dawg, ever, fuck, bitch, start, confus, shit]   \n",
       "3                               [look, like, tranni]   \n",
       "4  [shit, hear, about, might, true, might, faker,...   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [woman, shouldn, complain, about, cleaning, yo...   \n",
       "1                   [dat, cold, tyga, cuffin, place]   \n",
       "2   [Dawg, ever, fuck, bitch, start, confused, shit]   \n",
       "3                               [look, like, tranny]   \n",
       "4  [shit, hear, about, might, true, might, faker,...   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0  woman shouldn complain about cleaning your hou...   \n",
       "1                        dats cold tyga cuffin place   \n",
       "2           Dawg ever fuck bitch start confused shit   \n",
       "3                                   look like tranny   \n",
       "4  shit hear about might true might faker than bi...   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0  woman shouldn complain about cleaning your hou...  \n",
       "1                         dats cold tyga cuffin plac  \n",
       "2           dawg ever fuck bitch start confused shit  \n",
       "3                                   look like tranni  \n",
       "4  shit hear about might true might faker than bi...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count', 'hate_speech', 'offensive_language', 'neither', 'class',\n",
       "       'tweet', 'tidy_tweet', 'no_hash_tweet', 'tokenized_tweet',\n",
       "       'stemmed_tokens', 'lemmatized_tokens', 'lem_tweet', 'stem_tweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.774321\n",
       "2    0.167978\n",
       "0    0.057701\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=df[df['label']==0]\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= df[df['label']==1]\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lem_tweet = df.lem_tweet.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stem_tweet = df.stem_tweet.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/data2-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('data/cleaned-reshuffled.csv')\n",
    "# df.drop(['Unnamed: 0'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# cloud_mask = np.array(Image.open(\"twitter.png\"))\n",
    "# cloud_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "df_0_words = ' '.join([text for text in df['tidy_tweet'][df['label']==0]])\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=10, max_font_size=110).generate(df_0_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_words = ' '.join([text for text in df['tidy_tweet'][df['label']==1]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=210, max_font_size=110).generate(df_1_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect hashtags\n",
    "def hashtag_extract(tweet):\n",
    "    hashtags = []\n",
    "    # Loop over the words in the tweet\n",
    "    for word in tweet:\n",
    "        ht = re.findall(r\"#(\\w+)\", word)\n",
    "        hashtags.append(ht)\n",
    "\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting hashtags from non racist/sexist tweets\n",
    "HT_0 = hashtag_extract(df['tidy_tweet_2'][df['label']==0])\n",
    "\n",
    "# extracting hashtags from racist/sexist tweets\n",
    "HT_1 = hashtag_extract(df['tidy_tweet_2'][df['label']==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HT_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnesting lists\n",
    "HT_0 = sum(HT_0,[])\n",
    "HT_1 = sum(HT_1,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HT_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nltk.FreqDist(HT_0)\n",
    "d = pd.DataFrame({'Hashtag': list(a.keys()),\n",
    "                  'Count': list(a.values())})\n",
    "# selecting top 10 most frequent hashtags     \n",
    "d = d.nlargest(columns=\"Count\", n = 10) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nltk.FreqDist(HT_1)\n",
    "e = pd.DataFrame({'Hashtag': list(b.keys()), 'Count': list(b.values())})\n",
    "# selecting top 10 most frequent hashtags\n",
    "e = e.nlargest(columns=\"Count\", n = 10)   \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=e, x= \"Hashtag\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist = FreqDist(HT_1)\n",
    "meta_freqdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist.plot(10,cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist = FreqDist(HT_0)\n",
    "meta_freqdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_freqdist.plot(10,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "meta_finder = BigramCollocationFinder.from_words(df['no_hash_tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_scored = meta_finder.score_ngrams(bigram_measures.raw_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
