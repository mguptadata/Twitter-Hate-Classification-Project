{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "\n",
    "# NLTK/NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from nltk.collocations import *\n",
    "import gensim\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Sampling\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import sklearn.decomposition as decomposition\n",
    "\n",
    "#Visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import average_precision_score, auc, roc_curve, precision_recall_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cleaned-reshuffled.pkl', 'rb') as f:\n",
    "\tdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "      <td>[sad, to, see, the, scenes, of, hooligans, pre...</td>\n",
       "      <td>[sad, to, see, the, scene, of, hooligan, pre, ...</td>\n",
       "      <td>[sad, to, see, the, scene, of, hooligan, pre, ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy to be apa of...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, to, be, a...</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, to, be, a...</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, to, be, a...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil s bihday #lnic #lnicjustanevilbday ...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>you might be a libtard if #libtard #sjw #liber...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what are your goals find out here #smile</td>\n",
       "      <td>what are your goals find out here smile</td>\n",
       "      <td>[what, are, your, goals, find, out, here, smile]</td>\n",
       "      <td>[what, are, your, goal, find, out, here, smile]</td>\n",
       "      <td>[what, are, your, goal, find, out, here, smile]</td>\n",
       "      <td>what are your goals find out here smile</td>\n",
       "      <td>what are your goals find out here smil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  #gooddyeyoung #yoyoyo super happy to be apa of...   \n",
       "2  queen evil s bihday #lnic #lnicjustanevilbday ...   \n",
       "3  you might be a libtard if #libtard #sjw #liber...   \n",
       "4           what are your goals find out here #smile   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre engrus ...   \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...   \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...   \n",
       "3  you might be a libtard if libtard sjw liberal ...   \n",
       "4            what are your goals find out here smile   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0  [sad, to, see, the, scenes, of, hooligans, pre...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happy, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4   [what, are, your, goals, find, out, here, smile]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [sad, to, see, the, scene, of, hooligan, pre, ...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happi, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4    [what, are, your, goal, find, out, here, smile]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [sad, to, see, the, scene, of, hooligan, pre, ...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happy, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4    [what, are, your, goal, find, out, here, smile]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre engrus ...   \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...   \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...   \n",
       "3  you might be a libtard if libtard sjw liberal ...   \n",
       "4            what are your goals find out here smile   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0  sad to see the scenes of hooligans pre engrus ...  \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...  \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...  \n",
       "3  you might be a libtard if libtard sjw liberal ...  \n",
       "4             what are your goals find out here smil  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Val / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and test \n",
    "X_model, X_test, y_model, y_test = train_test_split(X, y, stratify = y,  test_size=0.20, random_state=123)\n",
    "\n",
    "#splitting \"model\" into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.20, random_state=123)\n",
    "\n",
    "# df_train_full = X_train.copy()\n",
    "# df_train_full['label']= y_train\n",
    "# train_full_df.to_csv('train_full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Vectorization and Method Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=.001)\n",
    "tfidf_ngram = TfidfVectorizer(ngram_range=(1,2), min_df=.001)\n",
    "tfidf_ngram2 = TfidfVectorizer(ngram_range=(2,3),min_df=.001)\n",
    "\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "rfc = RandomForestClassifier(random_state=10)\n",
    "nb = GaussianNB()\n",
    "svc = SVC(random_state=10)\n",
    "\n",
    "vectorization_list = [('COUNT_VECTORIZER', count_vect),\n",
    "                      ('TFIDF_VECTORIZER', tfidf_vectorizer),\n",
    "                      ('TFIDF_NGRAM_1_2', tfidf_ngram),\n",
    "                      ('TFIDF_NGRAM_2_3', tfidf_ngram2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_up2, y_train_up2, X_train_transf2, X_val_transf2 = \\\n",
    "upsample_training_data3(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, log, count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.lem_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_up2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_transf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_up.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.lem_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_transf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up, y_up, X_train_transformed, X_val_transformed = \\\n",
    "upsample_training_data3(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, LogisticRegression(), tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up.lem_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(X_train_up.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = count_vect.fit_transform(X_up)\n",
    "vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = count_vect.fit_transform(test)\n",
    "vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed, X_val_transformed, y_train_pred, y_val_pred, y_val_pred_prob, matrix, \\\n",
    "compare_metrics, compare_predictions = \\\n",
    "single_vector_model3(X_train_up.lem_tweet, y_train_up, X_val.lem_tweet, y_val, LogisticRegression(), count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed, X_val_transformed, y_train_pred, y_val_pred, y_val_pred_prob, matrix, \\\n",
    "compare_metrics, compare_predictions = \\\n",
    "upsample_vector_model(X_train_up.lem_tweet, y_train_up, X_val.lem_tweet, y_val, LogisticRegression(), count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed, X_val_transformed, y_train_pred, y_val_pred2, y_val_pred_prob, \\\n",
    "compare_predictions, metrics_dict2 = \\\n",
    "smote_vector_model2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, LogisticRegression(), count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20455, 28610)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed, X_val_transformed, y_train_pred, y_val_pred2, y_val_pred_prob, \\\n",
    "compare_predictions, metrics_dict2 = \\\n",
    "upsample_vector_model2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, LogisticRegression(), count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed, X_val_transformed, y_train_pred, y_val_pred2, y_val_pred_prob, \\\n",
    "compare_predictions, metrics_dict2 = \\\n",
    "downsample_vector_model2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, LogisticRegression(), count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix (y_val, y_val_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_down_transformed, X_val_transformed, y_train_down, y_val_pred2, yval_pp, \\\n",
    " compare_predictions, metrics_dict = \\\n",
    "upsample_vector_model2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, LogisticRegression(), count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_down_transformed, X_val_transformed, y_train_down, y_val_pred2, yval_pp, \\\n",
    " compare_predictions, metrics_dict = \\\n",
    "single_vector_model2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, LogisticRegression(), count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_val_t, y_train_pred, y_val_pred3, y_val_prob, metrics2, pred_df = \\\n",
    "wrapper_single_vectorization(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val,\n",
    "                              LogisticRegression(), count_vect, sampling='smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_val_t, y_train_pred, y_val_pred3, y_val_prob, metrics3, pred_df = \\\n",
    "wrapper_single_vectorization(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val,\n",
    "                              LogisticRegression(), count_vect, sampling='upsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_val_t, y_train_pred, y_val_pred3, y_val_prob, metrics3, pred_df = \\\n",
    "wrapper_single_vectorization(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val,\n",
    "                              LogisticRegression(), count_vect, sampling='downsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_val_t, y_train_pred, y_val_pred3, y_val_prob, metrics3, pred_df = \\\n",
    "wrapper_single_vectorization(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, log, count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results = downsample_compare_vectorization_model(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, \n",
    "                                                         LogisticRegression(penalty = 'l1', random_state=1),\n",
    "                                                         vectorization_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.93              0.85             0.84   \n",
       "Train F1                          0.93              0.85             0.84   \n",
       "Train Precision                   0.94              0.87             0.87   \n",
       "Train Recall                      0.91              0.82             0.81   \n",
       "Validation Accuracy               0.85              0.83             0.82   \n",
       "Validation F1                     0.40              0.35             0.35   \n",
       "Validation Precision              0.27              0.23             0.23   \n",
       "Validation Recall                 0.76              0.73             0.74   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.72  \n",
       "Train F1                         0.64  \n",
       "Train Precision                  0.90  \n",
       "Train Recall                     0.50  \n",
       "Validation Accuracy              0.86  \n",
       "Validation F1                    0.27  \n",
       "Validation Precision             0.21  \n",
       "Validation Recall                0.38  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results = \\\n",
    "wrapper_compare_vectorizations2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val,\n",
    "                             LogisticRegression(penalty='l1', random_state =1), \n",
    "                                vectorization_list, sampling = 'upsample')\n",
    "pd.DataFrame(metrics_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.93              0.85             0.84   \n",
       "Train F1                          0.93              0.85             0.84   \n",
       "Train Precision                   0.94              0.87             0.87   \n",
       "Train Recall                      0.91              0.82             0.81   \n",
       "Validation Accuracy               0.85              0.83             0.82   \n",
       "Validation F1                     0.40              0.35             0.35   \n",
       "Validation Precision              0.27              0.23             0.23   \n",
       "Validation Recall                 0.76              0.73             0.74   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.72  \n",
       "Train F1                         0.64  \n",
       "Train Precision                  0.90  \n",
       "Train Recall                     0.50  \n",
       "Validation Accuracy              0.86  \n",
       "Validation F1                    0.27  \n",
       "Validation Precision             0.21  \n",
       "Validation Recall                0.38  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results = \\\n",
    "wrapper_compare_vectorizations2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val,\n",
    "                             LogisticRegression(penalty='l1', random_state =1), \n",
    "                                vectorization_list, sampling = 'downsample')\n",
    "pd.DataFrame(metrics_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.97              0.95             0.95   \n",
       "Train F1                          0.79              0.53             0.52   \n",
       "Train Precision                   0.96              0.84             0.84   \n",
       "Train Recall                      0.67              0.39             0.38   \n",
       "Validation Accuracy               0.96              0.95             0.95   \n",
       "Validation F1                     0.62              0.50             0.48   \n",
       "Validation Precision              0.81              0.78             0.79   \n",
       "Validation Recall                 0.50              0.37             0.35   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.93  \n",
       "Train F1                         0.14  \n",
       "Train Precision                  0.91  \n",
       "Train Recall                     0.08  \n",
       "Validation Accuracy              0.94  \n",
       "Validation F1                    0.13  \n",
       "Validation Precision             0.96  \n",
       "Validation Recall                0.07  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results = \\\n",
    "wrapper_compare_vectorizations2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val,\n",
    "                             LogisticRegression(penalty='l1', random_state =1), \n",
    "                                vectorization_list)\n",
    "pd.DataFrame(metrics_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling method does not exist. Indicate: smote, upsample or downsample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results = \\\n",
    "wrapper_compare_vectorizations2(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val,\n",
    "                             LogisticRegression(penalty='l1', random_state =1), \n",
    "                                vectorization_list, sampling = 'gibberish')\n",
    "pd.DataFrame(metrics_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_compare_vectorization_model(X_train.lem_tweet, y_train, \n",
    "                                   X_val.lem_tweet, y_val, GaussianNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.95             0.95   \n",
       "Train F1                          0.89              0.48             0.48   \n",
       "Train Precision                   0.99              0.88             0.89   \n",
       "Train Recall                      0.81              0.33             0.33   \n",
       "Validation Accuracy               0.96              0.95             0.95   \n",
       "Validation F1                     0.62              0.44             0.43   \n",
       "Validation Precision              0.86              0.84             0.88   \n",
       "Validation Recall                 0.49              0.30             0.29   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.93  \n",
       "Train F1                         0.14  \n",
       "Train Precision                  0.93  \n",
       "Train Recall                     0.08  \n",
       "Validation Accuracy              0.94  \n",
       "Validation F1                    0.13  \n",
       "Validation Precision             0.96  \n",
       "Validation Recall                0.07  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers with no presets\n",
    "lr_results1 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(solver = 'lbfgs', random_state = 10), \n",
    "                                            vectorization_list)\n",
    "\n",
    "lr_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.89             0.90   \n",
       "Train F1                          0.93              0.55             0.58   \n",
       "Train Precision                   0.86              0.39             0.41   \n",
       "Train Recall                      0.99              0.92             0.94   \n",
       "Validation Accuracy               0.95              0.87             0.88   \n",
       "Validation F1                     0.66              0.43             0.44   \n",
       "Validation Precision              0.62              0.30             0.31   \n",
       "Validation Recall                 0.71              0.75             0.74   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.54  \n",
       "Train F1                         0.23  \n",
       "Train Precision                  0.13  \n",
       "Train Recall                     0.92  \n",
       "Validation Accuracy              0.52  \n",
       "Validation F1                    0.18  \n",
       "Validation Precision             0.10  \n",
       "Validation Recall                0.83  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + class balances\n",
    "lr_results2 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(class_weight= 'balanced', \n",
    "                            solver = 'lbfgs', random_state = 10), vectorization_list)\n",
    "lr_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.94             0.96   \n",
       "Train F1                          0.99              0.94             0.96   \n",
       "Train Precision                   0.99              0.93             0.94   \n",
       "Train Recall                      1.00              0.96             0.98   \n",
       "Validation Accuracy               0.95              0.91             0.91   \n",
       "Validation F1                     0.65              0.51             0.53   \n",
       "Validation Precision              0.62              0.38             0.41   \n",
       "Validation Recall                 0.68              0.76             0.76   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.80  \n",
       "Train F1                         0.77  \n",
       "Train Precision                  0.88  \n",
       "Train Recall                     0.69  \n",
       "Validation Accuracy              0.87  \n",
       "Validation F1                    0.32  \n",
       "Validation Precision             0.24  \n",
       "Validation Recall                0.47  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + upsampling\n",
    "lr_results3 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(solver = 'lbfgs', \n",
    "                            random_state = 10), vectorization_list, sampling = 'upsample')\n",
    "lr_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.92             0.93   \n",
       "Train F1                          0.99              0.92             0.93   \n",
       "Train Precision                   0.99              0.91             0.92   \n",
       "Train Recall                      0.99              0.92             0.93   \n",
       "Validation Accuracy               0.86              0.84             0.84   \n",
       "Validation F1                     0.42              0.40             0.40   \n",
       "Validation Precision              0.29              0.26             0.27   \n",
       "Validation Recall                 0.82              0.82             0.81   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.81  \n",
       "Train F1                         0.79  \n",
       "Train Precision                  0.90  \n",
       "Train Recall                     0.71  \n",
       "Validation Accuracy              0.82  \n",
       "Validation F1                    0.29  \n",
       "Validation Precision             0.19  \n",
       "Validation Recall                0.54  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + downsampling\n",
    "lr_results4 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(random_state = 10, solver = 'lbfgs'), \n",
    "                            vectorization_list, sampling = 'downsample')\n",
    "lr_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-13a49d6bbdb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlem_tweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             vectorization_list, sampling = 'smote')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlr_results5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-c9a8e93c7edf>\u001b[0m in \u001b[0;36mwrapper_compare_vectorizations\u001b[0;34m(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list, sampling, sample_class)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'smote'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote_compare_vectorization_model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorization_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'upsample'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-28f479e5c4b1>\u001b[0m in \u001b[0;36msmote_compare_vectorization_model2\u001b[0;34m(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list, sample_class)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_resample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 X, y, fitted_transformer = fit_resample_one_cached(\n\u001b[0;32m--> 201\u001b[0;31m                     cloned_transformer, X, y, **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_resample_one\u001b[0;34m(sampler, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_resample_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m             self.sampling_strategy, y, self._sampling_type)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/imblearn/over_sampling/_smote.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + smote\n",
    "lr_results5 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(random_state = 10, solver = 'lbfgs'), \n",
    "                            vectorization_list, sampling = 'smote')\n",
    "lr_results5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.96              0.90             0.90   \n",
       "Train F1                          0.77              0.54             0.56   \n",
       "Train Precision                   0.68              0.40             0.42   \n",
       "Train Recall                      0.88              0.84             0.85   \n",
       "Validation Accuracy               0.89              0.88             0.89   \n",
       "Validation F1                     0.45              0.44             0.44   \n",
       "Validation Precision              0.34              0.31             0.32   \n",
       "Validation Recall                 0.68              0.72             0.71   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.57  \n",
       "Train F1                         0.22  \n",
       "Train Precision                  0.13  \n",
       "Train Recall                     0.87  \n",
       "Validation Accuracy              0.55  \n",
       "Validation F1                    0.18  \n",
       "Validation Precision             0.10  \n",
       "Validation Recall                0.78  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + smote\n",
    "lr_results7 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(random_state = 10, solver = 'lbfgs'), \n",
    "                            vectorization_list, sampling = 'smote', sample_class= 'all')\n",
    "lr_results7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + smote\n",
    "lr_results7 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(random_state = 10, solver = 'lbfgs'), \n",
    "                            vectorization_list, sampling = 'smote', sample_class='not majority')\n",
    "lr_results7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mycsvfile.csv','a') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(LR_cw_lemm.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame.from_dict(data= LR_cw_lemm).to_csv('dict_file.csv', header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Final Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = wrapper_compare_vectorizations(X_train_up.lem_tweet, y_train_up, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(class_weight='balanced', penalty = 'l1'), \n",
    "                            vectorization_list, sampling='help')\n",
    "pd.DataFrame(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_predictions_val = []\n",
    "for item in logreg.predict_proba(X_val_transformed):\n",
    "    if item[0] <= .85:\n",
    "        weighted_predictions_val.append(1)\n",
    "    else:\n",
    "        weighted_predictions_val.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with threshhold adjustment\n",
    "pd.DataFrame(confusion_matrix(y_val, weighted_predictions_val), index = ['actual 0', 'actual 1'], columns = ['predicted 0', 'predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[pred_df['actual_class'] != pred_df['predicted_class']]\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['weighted_predictions'] = weighted_predictions_val\n",
    "pred_df[pred_df['actual_class'] != pred_df['weighted_predictions']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tweet[11418]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed, metrics_dict, train_confusion_matrix, y_test_pred, y_test_prob, test_df = \\\n",
    "\\\n",
    "wrapper_single_vectorization(X_train_up.lem_tweet, y_train_up, X_test.lem_tweet, y_test, \n",
    "                            logreg, count_vect, apply_smote = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class weight = balanced + lemmatized\n",
    "svm_metrics_balance, svm_X_train_transformed, svm_X_val_transformed = \\\n",
    "wrapper_compare_vectorizations(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, \n",
    "                                   SVC(class_weight ='balanced', gamma='auto', random_state = 10), vectorization_list, apply_smote=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_metrics_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE + lemmatized \n",
    "svm_metrics_smote, svm_X_train_smote, svm_X_val_smote   = \\\n",
    "wrapper_compare_vectorizations(X_train.lem_tweet, y_train, X_val.lem_tweet, y_val, \n",
    "                                   SVC(class_weight ='balanced', gamma='auto', random_state = 10), vectorization_list, apply_smote=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_metrics_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsampling + lemmatized\n",
    "svm_metrics_up, svm_X_train_up, svm_X_val_up = \\\n",
    "wrapper_compare_vectorizations(X_train_up.lem_tweet, y_train, X_val_up.lem_tweet, y_val, \n",
    "                                   SVC(gamma='auto', random_state = 10), vectorization_list, apply_smote=False)\n",
    "pd.DataFrame(svm_metrics_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Searching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfid2 =  tfidf_ngram2.fit_transform(X_train_up.lemmatized_tweet)\n",
    "X_val_tfid2 =  tfidf_ngram2.transform(X_val.lemmatized_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(kernel='linear', C=1, gamma=1, class_weight ='balanced')\n",
    "\n",
    "params = {\n",
    "'C': [0.1,.2, .3, 0.8,1,1.2,1.4],\n",
    "'kernel':['linear', 'rbf'],\n",
    "'gamma' :[0.1,0.8,1,1.2,1.4]\n",
    "}\n",
    "\n",
    "svm_gs= GridSearchCV(svc, param_grid = params, cv = 3)\n",
    "\n",
    "scores = ['f1','accuracy','recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_gs.fit(X_train_tfid2, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_vector_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_vectorization_model(X_train_up.lemmatized_tweet, y_train_up, X_val.lemmatized_tweet, y_val, \n",
    "                                   SVC(C=1.2, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1.4, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  RandomForestClassifier(max_depth= 20, \n",
    "                                   n_estimators = 100, class_weight='balanced', random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.99             0.99   \n",
       "Train F1                          0.96              0.94             0.94   \n",
       "Train Precision                   1.00              1.00             1.00   \n",
       "Train Recall                      0.92              0.88             0.89   \n",
       "Validation Accuracy               0.96              0.96             0.96   \n",
       "Validation F1                     0.59              0.55             0.57   \n",
       "Validation Precision              0.92              0.83             0.84   \n",
       "Validation Recall                 0.43              0.41             0.43   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.95  \n",
       "Train F1                         0.43  \n",
       "Train Precision                  0.93  \n",
       "Train Recall                     0.28  \n",
       "Validation Accuracy              0.94  \n",
       "Validation F1                    0.17  \n",
       "Validation Precision             0.58  \n",
       "Validation Recall                0.10  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing; no hyperparameter tuning\n",
    "rfc_results1 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), vectorization_list)\n",
    "rfc_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.99             0.99   \n",
       "Train F1                          0.95              0.94             0.93   \n",
       "Train Precision                   1.00              0.97             0.97   \n",
       "Train Recall                      0.91              0.90             0.90   \n",
       "Validation Accuracy               0.96              0.95             0.95   \n",
       "Validation F1                     0.50              0.52             0.51   \n",
       "Validation Precision              0.96              0.80             0.77   \n",
       "Validation Recall                 0.34              0.39             0.38   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.62  \n",
       "Train F1                         0.25  \n",
       "Train Precision                  0.15  \n",
       "Train Recall                     0.92  \n",
       "Validation Accuracy              0.58  \n",
       "Validation F1                    0.18  \n",
       "Validation Precision             0.10  \n",
       "Validation Recall                0.71  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and class weights balanced\n",
    "rfc_results2 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10, class_weight = 'balanced'), \n",
    "                            vectorization_list)\n",
    "rfc_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    1.00              1.00             1.00   \n",
       "Train F1                          1.00              1.00             1.00   \n",
       "Train Precision                   1.00              1.00             1.00   \n",
       "Train Recall                      1.00              1.00             1.00   \n",
       "Validation Accuracy               0.96              0.95             0.96   \n",
       "Validation F1                     0.57              0.57             0.58   \n",
       "Validation Precision              0.86              0.73             0.78   \n",
       "Validation Recall                 0.42              0.47             0.47   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.85  \n",
       "Train F1                         0.83  \n",
       "Train Precision                  0.94  \n",
       "Train Recall                     0.74  \n",
       "Validation Accuracy              0.91  \n",
       "Validation F1                    0.36  \n",
       "Validation Precision             0.32  \n",
       "Validation Recall                0.40  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and upsampling\n",
    "rfc_results3 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), \n",
    "                            vectorization_list, sampling = 'upsample')\n",
    "rfc_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.99             0.99   \n",
       "Train F1                          0.99              0.99             0.99   \n",
       "Train Precision                   1.00              1.00             0.99   \n",
       "Train Recall                      0.98              0.99             0.99   \n",
       "Validation Accuracy               0.85              0.85             0.83   \n",
       "Validation F1                     0.38              0.39             0.36   \n",
       "Validation Precision              0.26              0.26             0.23   \n",
       "Validation Recall                 0.71              0.73             0.75   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.86  \n",
       "Train F1                         0.85  \n",
       "Train Precision                  0.96  \n",
       "Train Recall                     0.76  \n",
       "Validation Accuracy              0.81  \n",
       "Validation F1                    0.27  \n",
       "Validation Precision             0.18  \n",
       "Validation Recall                0.54  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and downsampling\n",
    "rfc_results4 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), \n",
    "                            vectorization_list, sampling = 'downsample')\n",
    "rfc_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              1.00             1.00   \n",
       "Train F1                          0.95              0.98             0.98   \n",
       "Train Precision                   0.95              0.98             0.98   \n",
       "Train Recall                      0.96              0.98             0.98   \n",
       "Validation Accuracy               0.89              0.94             0.94   \n",
       "Validation F1                     0.37              0.49             0.51   \n",
       "Validation Precision              0.29              0.51             0.51   \n",
       "Validation Recall                 0.51              0.47             0.50   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.64  \n",
       "Train F1                         0.26  \n",
       "Train Precision                  0.15  \n",
       "Train Recall                     0.87  \n",
       "Validation Accuracy              0.59  \n",
       "Validation F1                    0.18  \n",
       "Validation Precision             0.10  \n",
       "Validation Recall                0.69  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and smote\n",
    "rfc_results5 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), \n",
    "                            vectorization_list, sampling = 'smote')\n",
    "rfc_results5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Searching For Best Fit for Count Vectorizer + Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_countvect =  count_vect.fit_transform(X_train.lem_tweet)\n",
    "X_val_countvect =  count_vect.transform(X_val.lem_tweet)\n",
    "X_test_countvect = count_vect.transform(X_test.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=10)\n",
    "\n",
    "parameters = {'n_estimators' : [40, 60, 80, 100],\n",
    "'max_leaf_nodes' : [200, 400, 600],\n",
    "'random_state' : [10],\n",
    "'max_depth': [5, 7, 10, 20],\n",
    " 'verbose' : [0],\n",
    "'class_weight': ['balanced', 'balanced_subsample']}\n",
    "          \n",
    "rfc_gs = GridSearchCV(rfc, param_grid=parameters, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs.fit(X_train_countvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "                       criterion='gini', max_depth=20, max_features='auto',\n",
    "                       max_leaf_nodes=200, min_impurity_decrease=0.0,\n",
    "                       min_impurity_split=None, min_samples_leaf=1,\n",
    "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                       random_state=10, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2.fit(X_train_countvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = rfc2.predict(X_train_countvect)\n",
    "metrics.f1_score(y_train, y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predict = rfc2.predict(X_val_countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_val, y_val_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_feature_importances(rfc2):\n",
    "    n_features = X_val_countvect.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), rfc2.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), countvect.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "plot_feature_importances(rfc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.tokenized_tweet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train.tokenized_tweet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-train pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.tokenized_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token_list = list(X_train.tokenized_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_token_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token_sumlist = sum(X_train_token_list,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unique_tokens = set(X_train_token_sumlist)\n",
    "print('The unique number of words in the training dataset is: {}'.format(len(X_train_unique_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X-val pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_token_list = list(X_val['tokenized_tweet'])\n",
    "X_val_token_sumlist = sum(X_val_token_list,[])\n",
    "X_val_unique_tokens = set(X_val_token_sumlist)\n",
    "\n",
    "print('The unique number of words in the validation dataset is: {}'.format(len(X_val_unique_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X-test pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_token_list = list(X_test['tokenized_tweet'])\n",
    "X_test_token_sumlist = sum(X_test_token_list,[])\n",
    "\n",
    "X_test_unique_tokens = set(X_test_token_sumlist)\n",
    "print('The unique number of words in the training dataset is: {}'.format(len(X_test_unique_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train_token_list, sg=1, min_count=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.train(X_train_token_list, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('data/w2v.model')\n",
    "\n",
    "w2v = gensim.models.Word2Vec.load('data/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vocab= w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w2v_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv['trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(['trump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(['racist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(positive=['lazy','black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.get_keras_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_X = w2v.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = X_train_token_list[1]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create average vector for train and test from model\n",
    "#returned list of numpy arrays are then stacked \n",
    "\n",
    "X_train_w2v_2 = np.concatenate([avg_word_vectors(word, w2v) for word in X_train_token_list])\n",
    "\n",
    "X_val_w2v_2 = np.concatenate([avg_word_vectors(word, w2v) for word in X_val_token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_2[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_w2v_model(X_train_w2v, y_train, X_val_w2v, y_val, LogisticRegression(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_w2v_model(X_train_w2v_2, y_train, X_val_w2v_2, y_val, LogisticRegression(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_w2v_model(X_train_w2v_2, y_train, X_val_w2v_2, y_val, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# glove_input_file = 'data/glove.twitter.27B.100d.txt'\n",
    "# glove_output_file = 'data/glove.txt.word2vec'\n",
    "# glove2word2vec(glove_input_file, glove_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format('data/glove.txt.word2vec', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model.most_similar('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove2 = np.empty((20455, 100))\n",
    "for sentence in X_train_token_list:\n",
    "    np.append(X_train_glove2, np.mean([glove_model[w] for w in sentence if w in glove_model]\n",
    "                   or [np.zeros(100)], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove = np.concatenate([avg_word_vectors(w, glove_model) for w in X_train_token_list])\n",
    "X_val_glove = np.concatenate([avg_word_vectors(w, glove_model) for w in X_val_token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove[255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_w2v_model (X_train_glove, y_train, X_val_glove, y_val, LogisticRegression (class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Testing Scraped Trump Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trump_df= pd.read_csv('data/cleaned-trump-tweet.csv')\n",
    "trump_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_countvect =  count_vect.fit_transform(X_train_up.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train_countvect, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump = count_vect.transform(trump_df.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump = X_trump.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict = logreg.predict(X_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['predictions'] = y_trump_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict_prob = logreg.predict_proba(X_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict_prob = pd.DataFrame(y_trump_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['predict_probability'] = y_trump_predict_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df = trump_df[['tweet','predictions', 'predict_probability']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump0 = trump_df[trump_df.predictions == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump0.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df[trump_df.predictions == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump1 = trump_df[trump_df.predictions == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump1.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
