{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Predicting on Scraped Trump Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trump_tweet_cleaned.pkl', 'rb') as f:\n",
    "\tdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAKE AMERICA GREAT AGAIN!</td>\n",
       "      <td>make america great again</td>\n",
       "      <td>make america great again</td>\n",
       "      <td>[make, america, great, again]</td>\n",
       "      <td>[make, america, great, again]</td>\n",
       "      <td>[make, america, great, again]</td>\n",
       "      <td>make america great again</td>\n",
       "      <td>make america great again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With all that this Administration has accompli...</td>\n",
       "      <td>with all that this administration has accompli...</td>\n",
       "      <td>with all that this administration has accompli...</td>\n",
       "      <td>[with, all, that, this, administration, has, a...</td>\n",
       "      <td>[with, all, that, this, administr, has, accomp...</td>\n",
       "      <td>[with, all, that, this, administration, ha, ac...</td>\n",
       "      <td>with all that this administration has accompli...</td>\n",
       "      <td>with all that this administration has accompli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.....”Journalism” has reached a new low in the...</td>\n",
       "      <td>journalism has reached a new low in the histor...</td>\n",
       "      <td>journalism has reached a new low in the histor...</td>\n",
       "      <td>[journalism, has, reached, a, new, low, in, th...</td>\n",
       "      <td>[journal, has, reach, a, new, low, in, the, hi...</td>\n",
       "      <td>[journalism, ha, reached, a, new, low, in, the...</td>\n",
       "      <td>journalism has reached a new low in the histor...</td>\n",
       "      <td>journalism has reached a new low in the histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Failing New York Times, in one of the most...</td>\n",
       "      <td>the failing new york times in one of the most ...</td>\n",
       "      <td>the failing new york times in one of the most ...</td>\n",
       "      <td>[the, failing, new, york, times, in, one, of, ...</td>\n",
       "      <td>[the, fail, new, york, time, in, one, of, the,...</td>\n",
       "      <td>[the, failing, new, york, time, in, one, of, t...</td>\n",
       "      <td>the failing new york times in one of the most ...</td>\n",
       "      <td>the failing new york times in one of the most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pic.twitter.com/JDS4zVfyBe</td>\n",
       "      <td>pic twitter com jds zvfybe</td>\n",
       "      <td>pic twitter com jds zvfybe</td>\n",
       "      <td>[pic, twitter, com, jds, zvfybe]</td>\n",
       "      <td>[pic, twitter, com, jds, zvfybe]</td>\n",
       "      <td>[pic, twitter, com, jds, zvfybe]</td>\n",
       "      <td>pic twitter com jds zvfybe</td>\n",
       "      <td>pic twitter com jds zvfyb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0                          MAKE AMERICA GREAT AGAIN!   \n",
       "1  With all that this Administration has accompli...   \n",
       "2  .....”Journalism” has reached a new low in the...   \n",
       "3  The Failing New York Times, in one of the most...   \n",
       "4                         pic.twitter.com/JDS4zVfyBe   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0                           make america great again   \n",
       "1  with all that this administration has accompli...   \n",
       "2  journalism has reached a new low in the histor...   \n",
       "3  the failing new york times in one of the most ...   \n",
       "4                         pic twitter com jds zvfybe   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0                           make america great again   \n",
       "1  with all that this administration has accompli...   \n",
       "2  journalism has reached a new low in the histor...   \n",
       "3  the failing new york times in one of the most ...   \n",
       "4                         pic twitter com jds zvfybe   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0                      [make, america, great, again]   \n",
       "1  [with, all, that, this, administration, has, a...   \n",
       "2  [journalism, has, reached, a, new, low, in, th...   \n",
       "3  [the, failing, new, york, times, in, one, of, ...   \n",
       "4                   [pic, twitter, com, jds, zvfybe]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0                      [make, america, great, again]   \n",
       "1  [with, all, that, this, administr, has, accomp...   \n",
       "2  [journal, has, reach, a, new, low, in, the, hi...   \n",
       "3  [the, fail, new, york, time, in, one, of, the,...   \n",
       "4                   [pic, twitter, com, jds, zvfybe]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0                      [make, america, great, again]   \n",
       "1  [with, all, that, this, administration, ha, ac...   \n",
       "2  [journalism, ha, reached, a, new, low, in, the...   \n",
       "3  [the, failing, new, york, time, in, one, of, t...   \n",
       "4                   [pic, twitter, com, jds, zvfybe]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0                           make america great again   \n",
       "1  with all that this administration has accompli...   \n",
       "2  journalism has reached a new low in the histor...   \n",
       "3  the failing new york times in one of the most ...   \n",
       "4                         pic twitter com jds zvfybe   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0                           make america great again  \n",
       "1  with all that this administration has accompli...  \n",
       "2  journalism has reached a new low in the histor...  \n",
       "3  the failing new york times in one of the most ...  \n",
       "4                          pic twitter com jds zvfyb  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_countvect =  count_vect.fit_transform(X_train_up.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train_countvect, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump = count_vect.transform(trump_df.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump = X_trump.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict = logreg.predict(X_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['predictions'] = y_trump_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict_prob = logreg.predict_proba(X_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict_prob = pd.DataFrame(y_trump_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['predict_probability'] = y_trump_predict_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df = trump_df[['tweet','predictions', 'predict_probability']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump0 = trump_df[trump_df.predictions == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump0.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df[trump_df.predictions == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump1 = trump_df[trump_df.predictions == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump1.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
