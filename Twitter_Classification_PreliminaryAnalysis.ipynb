{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "\n",
    "# NLTK/NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from nltk.collocations import *\n",
    "import gensim\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scikitplot as skplt\n",
    "\n",
    "#Sampling\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import sklearn.decomposition as decomposition\n",
    "\n",
    "#Visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import average_precision_score, auc, roc_curve, precision_recall_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cleaned-reshuffled.pkl', 'rb') as f:\n",
    "\tdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "      <td>[sad, to, see, the, scenes, of, hooligans, pre...</td>\n",
       "      <td>[sad, to, see, the, scene, of, hooligan, pre, ...</td>\n",
       "      <td>[sad, to, see, the, scene, of, hooligan, pre, ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy to be apa of...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, to, be, a...</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, to, be, a...</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, to, be, a...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil s bihday #lnic #lnicjustanevilbday ...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>you might be a libtard if #libtard #sjw #liber...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what are your goals find out here #smile</td>\n",
       "      <td>what are your goals find out here smile</td>\n",
       "      <td>[what, are, your, goals, find, out, here, smile]</td>\n",
       "      <td>[what, are, your, goal, find, out, here, smile]</td>\n",
       "      <td>[what, are, your, goal, find, out, here, smile]</td>\n",
       "      <td>what are your goals find out here smile</td>\n",
       "      <td>what are your goals find out here smil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  #gooddyeyoung #yoyoyo super happy to be apa of...   \n",
       "2  queen evil s bihday #lnic #lnicjustanevilbday ...   \n",
       "3  you might be a libtard if #libtard #sjw #liber...   \n",
       "4           what are your goals find out here #smile   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre engrus ...   \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...   \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...   \n",
       "3  you might be a libtard if libtard sjw liberal ...   \n",
       "4            what are your goals find out here smile   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0  [sad, to, see, the, scenes, of, hooligans, pre...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happy, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4   [what, are, your, goals, find, out, here, smile]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [sad, to, see, the, scene, of, hooligan, pre, ...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happi, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4    [what, are, your, goal, find, out, here, smile]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [sad, to, see, the, scene, of, hooligan, pre, ...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happy, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4    [what, are, your, goal, find, out, here, smile]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre engrus ...   \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...   \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...   \n",
       "3  you might be a libtard if libtard sjw liberal ...   \n",
       "4            what are your goals find out here smile   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0  sad to see the scenes of hooligans pre engrus ...  \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...  \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...  \n",
       "3  you might be a libtard if libtard sjw liberal ...  \n",
       "4             what are your goals find out here smil  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Val / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and test \n",
    "X_model, X_test, y_model, y_test = train_test_split(X, y, stratify = y, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting \"model\" into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, stratify = y_model, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Vectorization and Method Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=.001)\n",
    "tfidf_ngram = TfidfVectorizer(ngram_range=(1,2), min_df=.001)\n",
    "tfidf_ngram2 = TfidfVectorizer(ngram_range=(2,3),min_df=.001)\n",
    "\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "rfc = RandomForestClassifier(random_state=10)\n",
    "nb = MultinomialNB()\n",
    "svc = SVC(random_state=10)\n",
    "\n",
    "vectorization_list = [('COUNT_VECTORIZER', count_vect),\n",
    "                      ('TFIDF_VECTORIZER', tfidf_vectorizer),\n",
    "                      ('TFIDF_NGRAM_1_2', tfidf_ngram),\n",
    "                      ('TFIDF_NGRAM_2_3', tfidf_ngram2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.97              0.94             0.94   \n",
       "Train F1                          0.74              0.36             0.37   \n",
       "Train Precision                   0.83              0.90             0.91   \n",
       "Train Recall                      0.66              0.23             0.23   \n",
       "Validation Accuracy               0.96              0.94             0.94   \n",
       "Validation F1                     0.60              0.36             0.35   \n",
       "Validation Precision              0.86              0.89             0.86   \n",
       "Validation Recall                 0.46              0.22             0.22   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.93  \n",
       "Train F1                         0.14  \n",
       "Train Precision                  0.89  \n",
       "Train Recall                     0.08  \n",
       "Validation Accuracy              0.93  \n",
       "Validation F1                    0.13  \n",
       "Validation Precision             0.87  \n",
       "Validation Recall                0.07  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_results1 = compare_vectorization_model(X_train.lem_tweet, y_train, \n",
    "                                   X_val.lem_tweet, y_val, MultinomialNB(), vectorization_list)\n",
    "\n",
    "nb_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results1.to_csv('data/NB_results.csv', mode = 'a', header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.97              0.90             0.91   \n",
       "Train F1                          0.97              0.90             0.91   \n",
       "Train Precision                   0.96              0.90             0.91   \n",
       "Train Recall                      0.99              0.91             0.90   \n",
       "Validation Accuracy               0.92              0.89             0.90   \n",
       "Validation F1                     0.57              0.51             0.53   \n",
       "Validation Precision              0.45              0.37             0.40   \n",
       "Validation Recall                 0.79              0.81             0.78   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.77  \n",
       "Train F1                         0.73  \n",
       "Train Precision                  0.89  \n",
       "Train Recall                     0.61  \n",
       "Validation Accuracy              0.88  \n",
       "Validation F1                    0.35  \n",
       "Validation Precision             0.29  \n",
       "Validation Recall                0.45  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_results3 = wrapper_compare_vectorizations(X_train.lem_tweet, y_train, \n",
    "                                   X_val.lem_tweet, y_val, MultinomialNB(), \n",
    "                                    vectorization_list, sampling = 'upsample')\n",
    "nb_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results3.to_csv('data/NB_results.csv', mode = 'a', header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.97              0.92             0.93   \n",
       "Train F1                          0.97              0.92             0.93   \n",
       "Train Precision                   0.97              0.92             0.94   \n",
       "Train Recall                      0.98              0.92             0.93   \n",
       "Validation Accuracy               0.84              0.85             0.86   \n",
       "Validation F1                     0.44              0.45             0.45   \n",
       "Validation Precision              0.29              0.31             0.31   \n",
       "Validation Recall                 0.89              0.86             0.83   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.81  \n",
       "Train F1                         0.78  \n",
       "Train Precision                  0.92  \n",
       "Train Recall                     0.68  \n",
       "Validation Accuracy              0.84  \n",
       "Validation F1                    0.32  \n",
       "Validation Precision             0.23  \n",
       "Validation Recall                0.53  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_results4 = wrapper_compare_vectorizations(X_train.lem_tweet, y_train, \n",
    "                                   X_val.lem_tweet, y_val, MultinomialNB(), \n",
    "                                    vectorization_list, sampling = 'downsample')\n",
    "nb_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results4.to_csv('data/NB_results.csv', mode = 'a', header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.96              0.88             0.88   \n",
       "Train F1                          0.76              0.50             0.51   \n",
       "Train Precision                   0.68              0.35             0.35   \n",
       "Train Recall                      0.85              0.89             0.90   \n",
       "Validation Accuracy               0.95              0.87             0.87   \n",
       "Validation F1                     0.64              0.46             0.46   \n",
       "Validation Precision              0.60              0.32             0.32   \n",
       "Validation Recall                 0.67              0.81             0.79   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.83  \n",
       "Train F1                         0.27  \n",
       "Train Precision                  0.19  \n",
       "Train Recall                     0.44  \n",
       "Validation Accuracy              0.83  \n",
       "Validation F1                    0.22  \n",
       "Validation Precision             0.16  \n",
       "Validation Recall                0.36  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_results5 = wrapper_compare_vectorizations(X_train.lem_tweet, y_train, \n",
    "                                   X_val.lem_tweet, y_val, MultinomialNB(), \n",
    "                                    vectorization_list, sampling = 'smote')\n",
    "nb_results5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results5.to_csv('data/NB_results.csv', mode = 'a', header ='column_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.95             0.95   \n",
       "Train F1                          0.89              0.47             0.47   \n",
       "Train Precision                   0.99              0.88             0.89   \n",
       "Train Recall                      0.80              0.32             0.32   \n",
       "Validation Accuracy               0.96              0.95             0.95   \n",
       "Validation F1                     0.64              0.48             0.45   \n",
       "Validation Precision              0.85              0.89             0.85   \n",
       "Validation Recall                 0.51              0.33             0.31   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.93  \n",
       "Train F1                         0.14  \n",
       "Train Precision                  0.96  \n",
       "Train Recall                     0.08  \n",
       "Validation Accuracy              0.93  \n",
       "Validation F1                    0.13  \n",
       "Validation Precision             0.87  \n",
       "Validation Recall                0.07  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers with no presets\n",
    "lr_results1 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(solver = 'lbfgs', random_state = 10), \n",
    "                                            vectorization_list)\n",
    "\n",
    "lr_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results1.to_csv('data/LR_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.89             0.90   \n",
       "Train F1                          0.93              0.54             0.56   \n",
       "Train Precision                   0.87              0.38             0.40   \n",
       "Train Recall                      0.99              0.92             0.93   \n",
       "Validation Accuracy               0.95              0.88             0.88   \n",
       "Validation F1                     0.66              0.48             0.48   \n",
       "Validation Precision              0.62              0.34             0.34   \n",
       "Validation Recall                 0.72              0.81             0.80   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.53  \n",
       "Train F1                         0.22  \n",
       "Train Precision                  0.12  \n",
       "Train Recall                     0.93  \n",
       "Validation Accuracy              0.51  \n",
       "Validation F1                    0.20  \n",
       "Validation Precision             0.11  \n",
       "Validation Recall                0.86  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + class balances\n",
    "lr_results2 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(class_weight= 'balanced', \n",
    "                            solver = 'lbfgs', random_state = 10), vectorization_list)\n",
    "lr_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results2.to_csv('data/LR_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.94             0.96   \n",
       "Train F1                          0.99              0.94             0.96   \n",
       "Train Precision                   0.99              0.92             0.94   \n",
       "Train Recall                      1.00              0.96             0.98   \n",
       "Validation Accuracy               0.95              0.91             0.92   \n",
       "Validation F1                     0.67              0.55             0.56   \n",
       "Validation Precision              0.63              0.43             0.44   \n",
       "Validation Recall                 0.70              0.77             0.77   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.79  \n",
       "Train F1                         0.77  \n",
       "Train Precision                  0.86  \n",
       "Train Recall                     0.70  \n",
       "Validation Accuracy              0.86  \n",
       "Validation F1                    0.34  \n",
       "Validation Precision             0.25  \n",
       "Validation Recall                0.50  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + upsampling\n",
    "lr_results3 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(solver = 'lbfgs', \n",
    "                            random_state = 10), vectorization_list, sampling = 'upsample')\n",
    "lr_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results3.to_csv('data/LR_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.93             0.94   \n",
       "Train F1                          0.99              0.93             0.94   \n",
       "Train Precision                   1.00              0.92             0.94   \n",
       "Train Recall                      0.99              0.94             0.95   \n",
       "Validation Accuracy               0.85              0.84             0.83   \n",
       "Validation F1                     0.44              0.42             0.41   \n",
       "Validation Precision              0.30              0.28             0.27   \n",
       "Validation Recall                 0.84              0.84             0.83   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.82  \n",
       "Train F1                         0.80  \n",
       "Train Precision                  0.91  \n",
       "Train Recall                     0.71  \n",
       "Validation Accuracy              0.82  \n",
       "Validation F1                    0.30  \n",
       "Validation Precision             0.21  \n",
       "Validation Recall                0.55  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + downsampling\n",
    "lr_results4 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(random_state = 10, solver = 'lbfgs'), \n",
    "                            vectorization_list, sampling = 'downsample')\n",
    "lr_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results4.to_csv('data/LR_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.96              0.89             0.90   \n",
       "Train F1                          0.75              0.52             0.55   \n",
       "Train Precision                   0.66              0.38             0.40   \n",
       "Train Recall                      0.87              0.83             0.84   \n",
       "Validation Accuracy               0.89              0.88             0.88   \n",
       "Validation F1                     0.48              0.47             0.47   \n",
       "Validation Precision              0.36              0.34             0.35   \n",
       "Validation Recall                 0.70              0.75             0.74   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.56  \n",
       "Train F1                         0.22  \n",
       "Train Precision                  0.13  \n",
       "Train Recall                     0.89  \n",
       "Validation Accuracy              0.54  \n",
       "Validation F1                    0.20  \n",
       "Validation Precision             0.11  \n",
       "Validation Recall                0.81  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression: compare vectorizers using lemmitizing + smote\n",
    "lr_results5 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            LogisticRegression(random_state = 10, solver = 'lbfgs'), \n",
    "                            vectorization_list, sampling = 'smote', sample_class = 'not majority')\n",
    "lr_results5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results5.to_csv('data/LR_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('mycsvfile.csv','a') as f:\n",
    "#     w = csv.writer(f)\n",
    "#     w.writerows(LR_cw_lemm.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pd.DataFrame.from_dict(data= LR_cw_lemm).to_csv('dict_file.csv', header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Searching with Upsampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "logreg = LogisticRegression(random_state= 10)\n",
    "\n",
    "c_space = np.linspace (.1, 10, 100)\n",
    "# c_space = np.logspace(-5, 8, 15)\n",
    "\n",
    "parameters = {'C': c_space, \n",
    "          'penalty': ['l1', 'l2']}\n",
    "\n",
    "scores = ['accuracy','recall','precision','f1']\n",
    "\n",
    "lr_gs = GridSearchCV(logreg, param_grid = parameters, \n",
    "                           verbose = 0, scoring = scores, cv = 3, refit = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs_model, X_val_transformed, pd.DataFrame(y_train_up_pred), pd.DataFrame(y_val_pred), y_val_prob, metrics_dict, pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs_model, lr_X_val, lr_y_train_pred, lr_y_val_pred, \\\n",
    "                lr_y_val_prob, lr_metrics_dict, lr_pred_df = \\\n",
    "wrapper_single_vectorization(X_train.lem_tweet, y_train, X_val.lem_tweet, \n",
    "                y_val, lr_gs, count_vect, sampling= 'upsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 8.4, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train Accuracy': 1.0,\n",
       " 'Train Precision': 1.0,\n",
       " 'Train Recall': 1.0,\n",
       " 'Train F1': 1.0,\n",
       " 'Validation Accuracy': 0.95,\n",
       " 'Validation Precision': 0.65,\n",
       " 'Validation Recall': 0.66,\n",
       " 'Validation F1': 0.65}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.261456</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.028860</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.879101</td>\n",
       "      <td>0.877287</td>\n",
       "      <td>0.887461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898588</td>\n",
       "      <td>0.895625</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>200</td>\n",
       "      <td>0.875880</td>\n",
       "      <td>0.875500</td>\n",
       "      <td>0.885867</td>\n",
       "      <td>0.879083</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281662</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.955442</td>\n",
       "      <td>0.958202</td>\n",
       "      <td>0.961120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946404</td>\n",
       "      <td>0.942777</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>197</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>0.961750</td>\n",
       "      <td>0.958969</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280229</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>0.029710</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.2</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.2, 'penalty': 'l1'}</td>\n",
       "      <td>0.926972</td>\n",
       "      <td>0.928864</td>\n",
       "      <td>0.932413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928292</td>\n",
       "      <td>0.927217</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>199</td>\n",
       "      <td>0.926461</td>\n",
       "      <td>0.929575</td>\n",
       "      <td>0.932737</td>\n",
       "      <td>0.929591</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346509</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>0.023607</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.2</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.2, 'penalty': 'l2'}</td>\n",
       "      <td>0.966562</td>\n",
       "      <td>0.966483</td>\n",
       "      <td>0.969006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955430</td>\n",
       "      <td>0.950890</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>195</td>\n",
       "      <td>0.967071</td>\n",
       "      <td>0.967285</td>\n",
       "      <td>0.969461</td>\n",
       "      <td>0.967939</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357371</td>\n",
       "      <td>0.033235</td>\n",
       "      <td>0.034816</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.3</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.30000000000000004, 'penalty': 'l1'}</td>\n",
       "      <td>0.953549</td>\n",
       "      <td>0.952997</td>\n",
       "      <td>0.954732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943402</td>\n",
       "      <td>0.941663</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>198</td>\n",
       "      <td>0.953916</td>\n",
       "      <td>0.953941</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>0.954387</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.416049</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.3</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.30000000000000004, 'penalty': 'l2'}</td>\n",
       "      <td>0.971451</td>\n",
       "      <td>0.969795</td>\n",
       "      <td>0.972476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958799</td>\n",
       "      <td>0.955230</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>193</td>\n",
       "      <td>0.971894</td>\n",
       "      <td>0.970450</td>\n",
       "      <td>0.972881</td>\n",
       "      <td>0.971742</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.369618</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>0.032667</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.4</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.4, 'penalty': 'l1'}</td>\n",
       "      <td>0.966956</td>\n",
       "      <td>0.962618</td>\n",
       "      <td>0.964117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948757</td>\n",
       "      <td>0.948191</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>196</td>\n",
       "      <td>0.967446</td>\n",
       "      <td>0.963448</td>\n",
       "      <td>0.964720</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.422871</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>0.022789</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.4</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.4, 'penalty': 'l2'}</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.972240</td>\n",
       "      <td>0.974132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960055</td>\n",
       "      <td>0.957814</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>191</td>\n",
       "      <td>0.974295</td>\n",
       "      <td>0.972793</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.973870</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.379938</td>\n",
       "      <td>0.057229</td>\n",
       "      <td>0.031639</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l1'}</td>\n",
       "      <td>0.970741</td>\n",
       "      <td>0.967192</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954219</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>194</td>\n",
       "      <td>0.971135</td>\n",
       "      <td>0.967896</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.969672</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.435108</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2'}</td>\n",
       "      <td>0.975473</td>\n",
       "      <td>0.973502</td>\n",
       "      <td>0.975552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961715</td>\n",
       "      <td>0.959373</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>189</td>\n",
       "      <td>0.975852</td>\n",
       "      <td>0.974018</td>\n",
       "      <td>0.975913</td>\n",
       "      <td>0.975261</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.349184</td>\n",
       "      <td>0.049646</td>\n",
       "      <td>0.027853</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.6</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.6, 'penalty': 'l1'}</td>\n",
       "      <td>0.973028</td>\n",
       "      <td>0.970584</td>\n",
       "      <td>0.971530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957600</td>\n",
       "      <td>0.955783</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>192</td>\n",
       "      <td>0.973418</td>\n",
       "      <td>0.971235</td>\n",
       "      <td>0.971957</td>\n",
       "      <td>0.972203</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.417373</td>\n",
       "      <td>0.015008</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.6</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.6, 'penalty': 'l2'}</td>\n",
       "      <td>0.977524</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.976341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.960533</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>187</td>\n",
       "      <td>0.977888</td>\n",
       "      <td>0.974395</td>\n",
       "      <td>0.976672</td>\n",
       "      <td>0.976318</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.376259</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.7000000000000001, 'penalty': 'l1'}</td>\n",
       "      <td>0.975158</td>\n",
       "      <td>0.972555</td>\n",
       "      <td>0.973738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959743</td>\n",
       "      <td>0.958040</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>190</td>\n",
       "      <td>0.975526</td>\n",
       "      <td>0.973132</td>\n",
       "      <td>0.974132</td>\n",
       "      <td>0.974263</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.451102</td>\n",
       "      <td>0.027511</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.7000000000000001, 'penalty': 'l2'}</td>\n",
       "      <td>0.977997</td>\n",
       "      <td>0.974763</td>\n",
       "      <td>0.978155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964883</td>\n",
       "      <td>0.961458</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>185</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>0.975244</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.977355</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.360951</td>\n",
       "      <td>0.037876</td>\n",
       "      <td>0.030008</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.8</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.8, 'penalty': 'l1'}</td>\n",
       "      <td>0.976656</td>\n",
       "      <td>0.973028</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961703</td>\n",
       "      <td>0.959585</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>188</td>\n",
       "      <td>0.976994</td>\n",
       "      <td>0.973583</td>\n",
       "      <td>0.975754</td>\n",
       "      <td>0.975443</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.470987</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.8</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.8, 'penalty': 'l2'}</td>\n",
       "      <td>0.978549</td>\n",
       "      <td>0.975473</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965359</td>\n",
       "      <td>0.962209</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>183</td>\n",
       "      <td>0.978898</td>\n",
       "      <td>0.975931</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.977999</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.385176</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.029149</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.9</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.9, 'penalty': 'l1'}</td>\n",
       "      <td>0.977366</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.976420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962912</td>\n",
       "      <td>0.960870</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>186</td>\n",
       "      <td>0.977678</td>\n",
       "      <td>0.974418</td>\n",
       "      <td>0.976759</td>\n",
       "      <td>0.976285</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.515956</td>\n",
       "      <td>0.032278</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.9</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.9, 'penalty': 'l2'}</td>\n",
       "      <td>0.978785</td>\n",
       "      <td>0.975868</td>\n",
       "      <td>0.979338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966247</td>\n",
       "      <td>0.962895</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>181</td>\n",
       "      <td>0.979126</td>\n",
       "      <td>0.976308</td>\n",
       "      <td>0.979624</td>\n",
       "      <td>0.978353</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.389024</td>\n",
       "      <td>0.032923</td>\n",
       "      <td>0.030887</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.977997</td>\n",
       "      <td>0.975868</td>\n",
       "      <td>0.976814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963366</td>\n",
       "      <td>0.961978</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>184</td>\n",
       "      <td>0.978286</td>\n",
       "      <td>0.976356</td>\n",
       "      <td>0.977146</td>\n",
       "      <td>0.977263</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.477736</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.979101</td>\n",
       "      <td>0.975946</td>\n",
       "      <td>0.979495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966544</td>\n",
       "      <td>0.963191</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>180</td>\n",
       "      <td>0.979433</td>\n",
       "      <td>0.976384</td>\n",
       "      <td>0.979776</td>\n",
       "      <td>0.978531</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.395781</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.034491</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>1.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.978785</td>\n",
       "      <td>0.976025</td>\n",
       "      <td>0.977760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964001</td>\n",
       "      <td>0.962638</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>182</td>\n",
       "      <td>0.979058</td>\n",
       "      <td>0.976507</td>\n",
       "      <td>0.978085</td>\n",
       "      <td>0.977883</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.487941</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>1.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.979338</td>\n",
       "      <td>0.976577</td>\n",
       "      <td>0.979653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966841</td>\n",
       "      <td>0.963594</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>178</td>\n",
       "      <td>0.979662</td>\n",
       "      <td>0.977007</td>\n",
       "      <td>0.979928</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.256995</td>\n",
       "      <td>0.025435</td>\n",
       "      <td>0.024093</td>\n",
       "      <td>0.011027</td>\n",
       "      <td>1.2</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.2000000000000002, 'penalty': 'l1'}</td>\n",
       "      <td>0.979574</td>\n",
       "      <td>0.976341</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964888</td>\n",
       "      <td>0.963384</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>179</td>\n",
       "      <td>0.979837</td>\n",
       "      <td>0.976809</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978396</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.481317</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>1.2</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.2000000000000002, 'penalty': 'l2'}</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977524</td>\n",
       "      <td>0.980521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967040</td>\n",
       "      <td>0.964026</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>177</td>\n",
       "      <td>0.980203</td>\n",
       "      <td>0.977946</td>\n",
       "      <td>0.980798</td>\n",
       "      <td>0.979649</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.591610</td>\n",
       "      <td>0.278470</td>\n",
       "      <td>0.031053</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>1.3</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.3000000000000003, 'penalty': 'l1'}</td>\n",
       "      <td>0.979653</td>\n",
       "      <td>0.976656</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966421</td>\n",
       "      <td>0.964138</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>176</td>\n",
       "      <td>0.979913</td>\n",
       "      <td>0.977111</td>\n",
       "      <td>0.980096</td>\n",
       "      <td>0.979040</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.491318</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.022952</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>1.3</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.3000000000000003, 'penalty': 'l2'}</td>\n",
       "      <td>0.980678</td>\n",
       "      <td>0.977603</td>\n",
       "      <td>0.980599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967188</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>175</td>\n",
       "      <td>0.980980</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.980874</td>\n",
       "      <td>0.979961</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.275403</td>\n",
       "      <td>0.040455</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>1.4</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.4000000000000001, 'penalty': 'l1'}</td>\n",
       "      <td>0.980521</td>\n",
       "      <td>0.977839</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966421</td>\n",
       "      <td>0.964891</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>173</td>\n",
       "      <td>0.980771</td>\n",
       "      <td>0.978263</td>\n",
       "      <td>0.980096</td>\n",
       "      <td>0.979710</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.495987</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.023022</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>1.4</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.4000000000000001, 'penalty': 'l2'}</td>\n",
       "      <td>0.980915</td>\n",
       "      <td>0.978155</td>\n",
       "      <td>0.980915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967495</td>\n",
       "      <td>0.964690</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>174</td>\n",
       "      <td>0.981208</td>\n",
       "      <td>0.978572</td>\n",
       "      <td>0.981185</td>\n",
       "      <td>0.980322</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.316438</td>\n",
       "      <td>0.033316</td>\n",
       "      <td>0.028799</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.5000000000000002, 'penalty': 'l1'}</td>\n",
       "      <td>0.980599</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>0.980284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.965197</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>171</td>\n",
       "      <td>0.980847</td>\n",
       "      <td>0.978648</td>\n",
       "      <td>0.980566</td>\n",
       "      <td>0.980020</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.496876</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>1.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.5000000000000002, 'penalty': 'l2'}</td>\n",
       "      <td>0.981151</td>\n",
       "      <td>0.978233</td>\n",
       "      <td>0.981073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967791</td>\n",
       "      <td>0.964985</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>172</td>\n",
       "      <td>0.981437</td>\n",
       "      <td>0.978648</td>\n",
       "      <td>0.981337</td>\n",
       "      <td>0.980474</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.542835</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>0.035104</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>8.6</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 8.6, 'penalty': 'l1'}</td>\n",
       "      <td>0.984621</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>0.983517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.967539</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>37</td>\n",
       "      <td>0.984831</td>\n",
       "      <td>0.980741</td>\n",
       "      <td>0.983772</td>\n",
       "      <td>0.983115</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.731491</td>\n",
       "      <td>0.083777</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>8.6</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 8.6, 'penalty': 'l2'}</td>\n",
       "      <td>0.982413</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970710</td>\n",
       "      <td>0.966637</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>145</td>\n",
       "      <td>0.982690</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984371</td>\n",
       "      <td>0.982446</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.463267</td>\n",
       "      <td>0.050117</td>\n",
       "      <td>0.027692</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>8.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 8.7, 'penalty': 'l1'}</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>0.983517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.967638</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>27</td>\n",
       "      <td>0.984984</td>\n",
       "      <td>0.980741</td>\n",
       "      <td>0.983772</td>\n",
       "      <td>0.983166</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.672291</td>\n",
       "      <td>0.024775</td>\n",
       "      <td>0.023102</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>8.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 8.7, 'penalty': 'l2'}</td>\n",
       "      <td>0.982492</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.966694</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>126</td>\n",
       "      <td>0.982767</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984766</td>\n",
       "      <td>0.982603</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.395387</td>\n",
       "      <td>0.055154</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>8.8</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 8.8, 'penalty': 'l1'}</td>\n",
       "      <td>0.984700</td>\n",
       "      <td>0.980521</td>\n",
       "      <td>0.983596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968951</td>\n",
       "      <td>0.967735</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>17</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.980893</td>\n",
       "      <td>0.983848</td>\n",
       "      <td>0.983216</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.648014</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>8.8</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 8.8, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>111</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984766</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.411133</td>\n",
       "      <td>0.055947</td>\n",
       "      <td>0.022518</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>8.9</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 8.9, 'penalty': 'l1'}</td>\n",
       "      <td>0.984621</td>\n",
       "      <td>0.980521</td>\n",
       "      <td>0.983517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.967636</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>28</td>\n",
       "      <td>0.984831</td>\n",
       "      <td>0.980893</td>\n",
       "      <td>0.983772</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.688176</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>8.9</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 8.9, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>111</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984766</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.548816</td>\n",
       "      <td>0.029841</td>\n",
       "      <td>0.030604</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>9</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.984937</td>\n",
       "      <td>0.980284</td>\n",
       "      <td>0.983438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.967447</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>47</td>\n",
       "      <td>0.985147</td>\n",
       "      <td>0.980665</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983169</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.746833</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>9</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>111</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984766</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.530503</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>9.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.980284</td>\n",
       "      <td>0.983438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.967397</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>51</td>\n",
       "      <td>0.985070</td>\n",
       "      <td>0.980665</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983144</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.760604</td>\n",
       "      <td>0.067941</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>9.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.966792</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>111</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984766</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.334897</td>\n",
       "      <td>0.032003</td>\n",
       "      <td>0.020778</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>9.2</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.2, 'penalty': 'l1'}</td>\n",
       "      <td>0.984937</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>0.983517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.967545</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>35</td>\n",
       "      <td>0.985147</td>\n",
       "      <td>0.980741</td>\n",
       "      <td>0.983772</td>\n",
       "      <td>0.983220</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.712256</td>\n",
       "      <td>0.035444</td>\n",
       "      <td>0.024146</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>9.2</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.2, 'penalty': 'l2'}</td>\n",
       "      <td>0.982571</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970584</td>\n",
       "      <td>0.966693</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>127</td>\n",
       "      <td>0.982843</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984690</td>\n",
       "      <td>0.982603</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.500440</td>\n",
       "      <td>0.031941</td>\n",
       "      <td>0.030040</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>9.3</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.3, 'penalty': 'l1'}</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.980205</td>\n",
       "      <td>0.983360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968506</td>\n",
       "      <td>0.967299</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>66</td>\n",
       "      <td>0.985070</td>\n",
       "      <td>0.980589</td>\n",
       "      <td>0.983619</td>\n",
       "      <td>0.983093</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.677203</td>\n",
       "      <td>0.022602</td>\n",
       "      <td>0.021999</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>9.3</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.3, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970584</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>120</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984690</td>\n",
       "      <td>0.982629</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.449458</td>\n",
       "      <td>0.076956</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>9.4</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.4, 'penalty': 'l1'}</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.980442</td>\n",
       "      <td>0.983438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968654</td>\n",
       "      <td>0.967494</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>41</td>\n",
       "      <td>0.985070</td>\n",
       "      <td>0.980817</td>\n",
       "      <td>0.983696</td>\n",
       "      <td>0.983194</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.701666</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>9.4</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.4, 'penalty': 'l2'}</td>\n",
       "      <td>0.982571</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.984464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970584</td>\n",
       "      <td>0.966693</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>127</td>\n",
       "      <td>0.982843</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.984690</td>\n",
       "      <td>0.982603</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.524368</td>\n",
       "      <td>0.117880</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>9.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.5, 'penalty': 'l1'}</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.980126</td>\n",
       "      <td>0.983281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968358</td>\n",
       "      <td>0.967201</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>73</td>\n",
       "      <td>0.985070</td>\n",
       "      <td>0.980513</td>\n",
       "      <td>0.983543</td>\n",
       "      <td>0.983042</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.693156</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>0.021183</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>9.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.5, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970435</td>\n",
       "      <td>0.966644</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>138</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980201</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.982578</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.414498</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>9.6</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.6, 'penalty': 'l1'}</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.980126</td>\n",
       "      <td>0.983281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968358</td>\n",
       "      <td>0.967151</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>77</td>\n",
       "      <td>0.984993</td>\n",
       "      <td>0.980513</td>\n",
       "      <td>0.983543</td>\n",
       "      <td>0.983017</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.706726</td>\n",
       "      <td>0.019546</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>9.6</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.6, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979732</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970435</td>\n",
       "      <td>0.966596</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>150</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980125</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.982553</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.538499</td>\n",
       "      <td>0.023887</td>\n",
       "      <td>0.031876</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>9.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.700000000000001, 'penalty': 'l1'}</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.980047</td>\n",
       "      <td>0.983202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968210</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>87</td>\n",
       "      <td>0.984993</td>\n",
       "      <td>0.980438</td>\n",
       "      <td>0.983467</td>\n",
       "      <td>0.982966</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.710161</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>9.7</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.700000000000001, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970435</td>\n",
       "      <td>0.966644</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>138</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980201</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.982578</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.506489</td>\n",
       "      <td>0.023176</td>\n",
       "      <td>0.031134</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>9.8</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.8, 'penalty': 'l1'}</td>\n",
       "      <td>0.985016</td>\n",
       "      <td>0.980126</td>\n",
       "      <td>0.983360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968506</td>\n",
       "      <td>0.967350</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>59</td>\n",
       "      <td>0.985223</td>\n",
       "      <td>0.980513</td>\n",
       "      <td>0.983619</td>\n",
       "      <td>0.983119</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.735933</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>9.8</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.8, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970435</td>\n",
       "      <td>0.966644</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>138</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980201</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.982578</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.446912</td>\n",
       "      <td>0.050745</td>\n",
       "      <td>0.028865</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>9.9</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 9.9, 'penalty': 'l1'}</td>\n",
       "      <td>0.984937</td>\n",
       "      <td>0.979968</td>\n",
       "      <td>0.983281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968358</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>76</td>\n",
       "      <td>0.985147</td>\n",
       "      <td>0.980362</td>\n",
       "      <td>0.983543</td>\n",
       "      <td>0.983017</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.728068</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.023833</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>9.9</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 9.9, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970435</td>\n",
       "      <td>0.966644</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>138</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980201</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.982578</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.416782</td>\n",
       "      <td>0.061002</td>\n",
       "      <td>0.043177</td>\n",
       "      <td>0.026694</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.984937</td>\n",
       "      <td>0.979968</td>\n",
       "      <td>0.983360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968506</td>\n",
       "      <td>0.967203</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>72</td>\n",
       "      <td>0.985147</td>\n",
       "      <td>0.980362</td>\n",
       "      <td>0.983619</td>\n",
       "      <td>0.983043</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.860784</td>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.022759</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>0.984306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970286</td>\n",
       "      <td>0.966595</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>151</td>\n",
       "      <td>0.982919</td>\n",
       "      <td>0.980201</td>\n",
       "      <td>0.984536</td>\n",
       "      <td>0.982552</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0         0.261456      0.017308         0.028860        0.004092     0.1   \n",
       "1         0.281662      0.004405         0.023493        0.000702     0.1   \n",
       "2         0.280229      0.032710         0.029710        0.009953     0.2   \n",
       "3         0.346509      0.021663         0.023607        0.001087     0.2   \n",
       "4         0.357371      0.033235         0.034816        0.005674     0.3   \n",
       "5         0.416049      0.045346         0.025063        0.001005     0.3   \n",
       "6         0.369618      0.013445         0.032667        0.001560     0.4   \n",
       "7         0.422871      0.011510         0.022789        0.001756     0.4   \n",
       "8         0.379938      0.057229         0.031639        0.000263     0.5   \n",
       "9         0.435108      0.022500         0.022111        0.000537     0.5   \n",
       "10        0.349184      0.049646         0.027853        0.008134     0.6   \n",
       "11        0.417373      0.015008         0.020969        0.000546     0.6   \n",
       "12        0.376259      0.013972         0.030954        0.000115     0.7   \n",
       "13        0.451102      0.027511         0.022561        0.001530     0.7   \n",
       "14        0.360951      0.037876         0.030008        0.003009     0.8   \n",
       "15        0.470987      0.015328         0.021800        0.000432     0.8   \n",
       "16        0.385176      0.010471         0.029149        0.002459     0.9   \n",
       "17        0.515956      0.032278         0.025372        0.002024     0.9   \n",
       "18        0.389024      0.032923         0.030887        0.000960       1   \n",
       "19        0.477736      0.008760         0.022705        0.000955       1   \n",
       "20        0.395781      0.023188         0.034491        0.005752     1.1   \n",
       "21        0.487941      0.006765         0.025303        0.001623     1.1   \n",
       "22        0.256995      0.025435         0.024093        0.011027     1.2   \n",
       "23        0.481317      0.011594         0.022865        0.000706     1.2   \n",
       "24        0.591610      0.278470         0.031053        0.000273     1.3   \n",
       "25        0.491318      0.003665         0.022952        0.001060     1.3   \n",
       "26        0.275403      0.040455         0.024288        0.011647     1.4   \n",
       "27        0.495987      0.012908         0.023022        0.001244     1.4   \n",
       "28        0.316438      0.033316         0.028799        0.007482     1.5   \n",
       "29        0.496876      0.027053         0.022232        0.000417     1.5   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "170       0.542835      0.036621         0.035104        0.003116     8.6   \n",
       "171       0.731491      0.083777         0.022567        0.001073     8.6   \n",
       "172       0.463267      0.050117         0.027692        0.006510     8.7   \n",
       "173       0.672291      0.024775         0.023102        0.002524     8.7   \n",
       "174       0.395387      0.055154         0.021320        0.006003     8.8   \n",
       "175       0.648014      0.003532         0.024202        0.001680     8.8   \n",
       "176       0.411133      0.055947         0.022518        0.005528     8.9   \n",
       "177       0.688176      0.020327         0.024690        0.002555     8.9   \n",
       "178       0.548816      0.029841         0.030604        0.001035       9   \n",
       "179       0.746833      0.101173         0.024164        0.001436       9   \n",
       "180       0.530503      0.061768         0.035520        0.005094     9.1   \n",
       "181       0.760604      0.067941         0.022388        0.000714     9.1   \n",
       "182       0.334897      0.032003         0.020778        0.000068     9.2   \n",
       "183       0.712256      0.035444         0.024146        0.003147     9.2   \n",
       "184       0.500440      0.031941         0.030040        0.006427     9.3   \n",
       "185       0.677203      0.022602         0.021999        0.000994     9.3   \n",
       "186       0.449458      0.076956         0.020126        0.002514     9.4   \n",
       "187       0.701666      0.008002         0.025820        0.003150     9.4   \n",
       "188       0.524368      0.117880         0.024171        0.003122     9.5   \n",
       "189       0.693156      0.029569         0.021183        0.002433     9.5   \n",
       "190       0.414498      0.069000         0.031700        0.005372     9.6   \n",
       "191       0.706726      0.019546         0.022926        0.001707     9.6   \n",
       "192       0.538499      0.023887         0.031876        0.000134     9.7   \n",
       "193       0.710161      0.013156         0.023658        0.001648     9.7   \n",
       "194       0.506489      0.023176         0.031134        0.000586     9.8   \n",
       "195       0.735933      0.020086         0.022758        0.001362     9.8   \n",
       "196       0.446912      0.050745         0.028865        0.009788     9.9   \n",
       "197       0.728068      0.048444         0.023833        0.000288     9.9   \n",
       "198       0.416782      0.061002         0.043177        0.026694      10   \n",
       "199       0.860784      0.130551         0.022759        0.003068      10   \n",
       "\n",
       "    param_penalty                                       params  \\\n",
       "0              l1                  {'C': 0.1, 'penalty': 'l1'}   \n",
       "1              l2                  {'C': 0.1, 'penalty': 'l2'}   \n",
       "2              l1                  {'C': 0.2, 'penalty': 'l1'}   \n",
       "3              l2                  {'C': 0.2, 'penalty': 'l2'}   \n",
       "4              l1  {'C': 0.30000000000000004, 'penalty': 'l1'}   \n",
       "5              l2  {'C': 0.30000000000000004, 'penalty': 'l2'}   \n",
       "6              l1                  {'C': 0.4, 'penalty': 'l1'}   \n",
       "7              l2                  {'C': 0.4, 'penalty': 'l2'}   \n",
       "8              l1                  {'C': 0.5, 'penalty': 'l1'}   \n",
       "9              l2                  {'C': 0.5, 'penalty': 'l2'}   \n",
       "10             l1                  {'C': 0.6, 'penalty': 'l1'}   \n",
       "11             l2                  {'C': 0.6, 'penalty': 'l2'}   \n",
       "12             l1   {'C': 0.7000000000000001, 'penalty': 'l1'}   \n",
       "13             l2   {'C': 0.7000000000000001, 'penalty': 'l2'}   \n",
       "14             l1                  {'C': 0.8, 'penalty': 'l1'}   \n",
       "15             l2                  {'C': 0.8, 'penalty': 'l2'}   \n",
       "16             l1                  {'C': 0.9, 'penalty': 'l1'}   \n",
       "17             l2                  {'C': 0.9, 'penalty': 'l2'}   \n",
       "18             l1                  {'C': 1.0, 'penalty': 'l1'}   \n",
       "19             l2                  {'C': 1.0, 'penalty': 'l2'}   \n",
       "20             l1                  {'C': 1.1, 'penalty': 'l1'}   \n",
       "21             l2                  {'C': 1.1, 'penalty': 'l2'}   \n",
       "22             l1   {'C': 1.2000000000000002, 'penalty': 'l1'}   \n",
       "23             l2   {'C': 1.2000000000000002, 'penalty': 'l2'}   \n",
       "24             l1   {'C': 1.3000000000000003, 'penalty': 'l1'}   \n",
       "25             l2   {'C': 1.3000000000000003, 'penalty': 'l2'}   \n",
       "26             l1   {'C': 1.4000000000000001, 'penalty': 'l1'}   \n",
       "27             l2   {'C': 1.4000000000000001, 'penalty': 'l2'}   \n",
       "28             l1   {'C': 1.5000000000000002, 'penalty': 'l1'}   \n",
       "29             l2   {'C': 1.5000000000000002, 'penalty': 'l2'}   \n",
       "..            ...                                          ...   \n",
       "170            l1                  {'C': 8.6, 'penalty': 'l1'}   \n",
       "171            l2                  {'C': 8.6, 'penalty': 'l2'}   \n",
       "172            l1                  {'C': 8.7, 'penalty': 'l1'}   \n",
       "173            l2                  {'C': 8.7, 'penalty': 'l2'}   \n",
       "174            l1                  {'C': 8.8, 'penalty': 'l1'}   \n",
       "175            l2                  {'C': 8.8, 'penalty': 'l2'}   \n",
       "176            l1                  {'C': 8.9, 'penalty': 'l1'}   \n",
       "177            l2                  {'C': 8.9, 'penalty': 'l2'}   \n",
       "178            l1                  {'C': 9.0, 'penalty': 'l1'}   \n",
       "179            l2                  {'C': 9.0, 'penalty': 'l2'}   \n",
       "180            l1                  {'C': 9.1, 'penalty': 'l1'}   \n",
       "181            l2                  {'C': 9.1, 'penalty': 'l2'}   \n",
       "182            l1                  {'C': 9.2, 'penalty': 'l1'}   \n",
       "183            l2                  {'C': 9.2, 'penalty': 'l2'}   \n",
       "184            l1                  {'C': 9.3, 'penalty': 'l1'}   \n",
       "185            l2                  {'C': 9.3, 'penalty': 'l2'}   \n",
       "186            l1                  {'C': 9.4, 'penalty': 'l1'}   \n",
       "187            l2                  {'C': 9.4, 'penalty': 'l2'}   \n",
       "188            l1                  {'C': 9.5, 'penalty': 'l1'}   \n",
       "189            l2                  {'C': 9.5, 'penalty': 'l2'}   \n",
       "190            l1                  {'C': 9.6, 'penalty': 'l1'}   \n",
       "191            l2                  {'C': 9.6, 'penalty': 'l2'}   \n",
       "192            l1    {'C': 9.700000000000001, 'penalty': 'l1'}   \n",
       "193            l2    {'C': 9.700000000000001, 'penalty': 'l2'}   \n",
       "194            l1                  {'C': 9.8, 'penalty': 'l1'}   \n",
       "195            l2                  {'C': 9.8, 'penalty': 'l2'}   \n",
       "196            l1                  {'C': 9.9, 'penalty': 'l1'}   \n",
       "197            l2                  {'C': 9.9, 'penalty': 'l2'}   \n",
       "198            l1                 {'C': 10.0, 'penalty': 'l1'}   \n",
       "199            l2                 {'C': 10.0, 'penalty': 'l2'}   \n",
       "\n",
       "     split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  ...  \\\n",
       "0                0.879101              0.877287              0.887461  ...   \n",
       "1                0.955442              0.958202              0.961120  ...   \n",
       "2                0.926972              0.928864              0.932413  ...   \n",
       "3                0.966562              0.966483              0.969006  ...   \n",
       "4                0.953549              0.952997              0.954732  ...   \n",
       "5                0.971451              0.969795              0.972476  ...   \n",
       "6                0.966956              0.962618              0.964117  ...   \n",
       "7                0.973896              0.972240              0.974132  ...   \n",
       "8                0.970741              0.967192              0.969479  ...   \n",
       "9                0.975473              0.973502              0.975552  ...   \n",
       "10               0.973028              0.970584              0.971530  ...   \n",
       "11               0.977524              0.973896              0.976341  ...   \n",
       "12               0.975158              0.972555              0.973738  ...   \n",
       "13               0.977997              0.974763              0.978155  ...   \n",
       "14               0.976656              0.973028              0.975394  ...   \n",
       "15               0.978549              0.975473              0.978864  ...   \n",
       "16               0.977366              0.973896              0.976420  ...   \n",
       "17               0.978785              0.975868              0.979338  ...   \n",
       "18               0.977997              0.975868              0.976814  ...   \n",
       "19               0.979101              0.975946              0.979495  ...   \n",
       "20               0.978785              0.976025              0.977760  ...   \n",
       "21               0.979338              0.976577              0.979653  ...   \n",
       "22               0.979574              0.976341              0.978233  ...   \n",
       "23               0.979890              0.977524              0.980521  ...   \n",
       "24               0.979653              0.976656              0.979811  ...   \n",
       "25               0.980678              0.977603              0.980599  ...   \n",
       "26               0.980521              0.977839              0.979811  ...   \n",
       "27               0.980915              0.978155              0.980915  ...   \n",
       "28               0.980599              0.978233              0.980284  ...   \n",
       "29               0.981151              0.978233              0.981073  ...   \n",
       "..                    ...                   ...                   ...  ...   \n",
       "170              0.984621              0.980363              0.983517  ...   \n",
       "171              0.982413              0.979890              0.984148  ...   \n",
       "172              0.984779              0.980363              0.983517  ...   \n",
       "173              0.982492              0.979890              0.984543  ...   \n",
       "174              0.984700              0.980521              0.983596  ...   \n",
       "175              0.982650              0.979890              0.984543  ...   \n",
       "176              0.984621              0.980521              0.983517  ...   \n",
       "177              0.982650              0.979890              0.984543  ...   \n",
       "178              0.984937              0.980284              0.983438  ...   \n",
       "179              0.982650              0.979890              0.984543  ...   \n",
       "180              0.984858              0.980284              0.983438  ...   \n",
       "181              0.982650              0.979890              0.984543  ...   \n",
       "182              0.984937              0.980363              0.983517  ...   \n",
       "183              0.982571              0.979890              0.984464  ...   \n",
       "184              0.984858              0.980205              0.983360  ...   \n",
       "185              0.982650              0.979890              0.984464  ...   \n",
       "186              0.984858              0.980442              0.983438  ...   \n",
       "187              0.982571              0.979890              0.984464  ...   \n",
       "188              0.984858              0.980126              0.983281  ...   \n",
       "189              0.982650              0.979811              0.984385  ...   \n",
       "190              0.984779              0.980126              0.983281  ...   \n",
       "191              0.982650              0.979732              0.984385  ...   \n",
       "192              0.984779              0.980047              0.983202  ...   \n",
       "193              0.982650              0.979811              0.984385  ...   \n",
       "194              0.985016              0.980126              0.983360  ...   \n",
       "195              0.982650              0.979811              0.984385  ...   \n",
       "196              0.984937              0.979968              0.983281  ...   \n",
       "197              0.982650              0.979811              0.984385  ...   \n",
       "198              0.984937              0.979968              0.983360  ...   \n",
       "199              0.982650              0.979811              0.984306  ...   \n",
       "\n",
       "     split2_test_precision  mean_test_precision  std_test_precision  \\\n",
       "0                 0.898588             0.895625            0.005108   \n",
       "1                 0.946404             0.942777            0.003661   \n",
       "2                 0.928292             0.927217            0.005202   \n",
       "3                 0.955430             0.950890            0.004550   \n",
       "4                 0.943402             0.941663            0.004768   \n",
       "5                 0.958799             0.955230            0.003867   \n",
       "6                 0.948757             0.948191            0.004420   \n",
       "7                 0.960055             0.957814            0.002863   \n",
       "8                 0.954219             0.953341            0.004400   \n",
       "9                 0.961715             0.959373            0.002824   \n",
       "10                0.957600             0.955783            0.004025   \n",
       "11                0.963190             0.960533            0.003139   \n",
       "12                0.959743             0.958040            0.003537   \n",
       "13                0.964883             0.961458            0.003283   \n",
       "14                0.961703             0.959585            0.004002   \n",
       "15                0.965359             0.962209            0.003062   \n",
       "16                0.962912             0.960870            0.003988   \n",
       "17                0.966247             0.962895            0.003091   \n",
       "18                0.963366             0.961978            0.003647   \n",
       "19                0.966544             0.963191            0.003171   \n",
       "20                0.964001             0.962638            0.003944   \n",
       "21                0.966841             0.963594            0.003108   \n",
       "22                0.964888             0.963384            0.004044   \n",
       "23                0.967040             0.964026            0.003021   \n",
       "24                0.966421             0.964138            0.004060   \n",
       "25                0.967188             0.964286            0.003241   \n",
       "26                0.966421             0.964891            0.003600   \n",
       "27                0.967495             0.964690            0.003192   \n",
       "28                0.966738             0.965197            0.003486   \n",
       "29                0.967791             0.964985            0.003289   \n",
       "..                     ...                  ...                 ...   \n",
       "170               0.968803             0.967539            0.003938   \n",
       "171               0.970710             0.966637            0.003701   \n",
       "172               0.968803             0.967638            0.004042   \n",
       "173               0.970732             0.966694            0.003720   \n",
       "174               0.968951             0.967735            0.003873   \n",
       "175               0.970732             0.966792            0.003747   \n",
       "176               0.968803             0.967636            0.003806   \n",
       "177               0.970732             0.966792            0.003747   \n",
       "178               0.968654             0.967447            0.003994   \n",
       "179               0.970732             0.966792            0.003747   \n",
       "180               0.968654             0.967397            0.003943   \n",
       "181               0.970732             0.966792            0.003747   \n",
       "182               0.968803             0.967545            0.003944   \n",
       "183               0.970584             0.966693            0.003680   \n",
       "184               0.968506             0.967299            0.003993   \n",
       "185               0.970584             0.966743            0.003695   \n",
       "186               0.968654             0.967494            0.003811   \n",
       "187               0.970584             0.966693            0.003680   \n",
       "188               0.968358             0.967201            0.004044   \n",
       "189               0.970435             0.966644            0.003709   \n",
       "190               0.968358             0.967151            0.003992   \n",
       "191               0.970435             0.966596            0.003776   \n",
       "192               0.968210             0.967053            0.004043   \n",
       "193               0.970435             0.966644            0.003709   \n",
       "194               0.968506             0.967350            0.004163   \n",
       "195               0.970435             0.966644            0.003709   \n",
       "196               0.968358             0.967153            0.004227   \n",
       "197               0.970435             0.966644            0.003709   \n",
       "198               0.968506             0.967203            0.004242   \n",
       "199               0.970286             0.966595            0.003659   \n",
       "\n",
       "     rank_test_precision  split0_test_f1  split1_test_f1  split2_test_f1  \\\n",
       "0                    200        0.875880        0.875500        0.885867   \n",
       "1                    197        0.956000        0.959155        0.961750   \n",
       "2                    199        0.926461        0.929575        0.932737   \n",
       "3                    195        0.967071        0.967285        0.969461   \n",
       "4                    198        0.953916        0.953941        0.955303   \n",
       "5                    193        0.971894        0.970450        0.972881   \n",
       "6                    196        0.967446        0.963448        0.964720   \n",
       "7                    191        0.974295        0.972793        0.974522   \n",
       "8                    194        0.971135        0.967896        0.969984   \n",
       "9                    189        0.975852        0.974018        0.975913   \n",
       "10                   192        0.973418        0.971235        0.971957   \n",
       "11                   187        0.977888        0.974395        0.976672   \n",
       "12                   190        0.975526        0.973132        0.974132   \n",
       "13                   185        0.978360        0.975244        0.978462   \n",
       "14                   188        0.976994        0.973583        0.975754   \n",
       "15                   183        0.978898        0.975931        0.979167   \n",
       "16                   186        0.977678        0.974418        0.976759   \n",
       "17                   181        0.979126        0.976308        0.979624   \n",
       "18                   184        0.978286        0.976356        0.977146   \n",
       "19                   180        0.979433        0.976384        0.979776   \n",
       "20                   182        0.979058        0.976507        0.978085   \n",
       "21                   178        0.979662        0.977007        0.979928   \n",
       "22                   179        0.979837        0.976809        0.978541   \n",
       "23                   177        0.980203        0.977946        0.980798   \n",
       "24                   176        0.979913        0.977111        0.980096   \n",
       "25                   175        0.980980        0.978029        0.980874   \n",
       "26                   173        0.980771        0.978263        0.980096   \n",
       "27                   174        0.981208        0.978572        0.981185   \n",
       "28                   171        0.980847        0.978648        0.980566   \n",
       "29                   172        0.981437        0.978648        0.981337   \n",
       "..                   ...             ...             ...             ...   \n",
       "170                   37        0.984831        0.980741        0.983772   \n",
       "171                  145        0.982690        0.980277        0.984371   \n",
       "172                   27        0.984984        0.980741        0.983772   \n",
       "173                  126        0.982767        0.980277        0.984766   \n",
       "174                   17        0.984907        0.980893        0.983848   \n",
       "175                  111        0.982919        0.980277        0.984766   \n",
       "176                   28        0.984831        0.980893        0.983772   \n",
       "177                  111        0.982919        0.980277        0.984766   \n",
       "178                   47        0.985147        0.980665        0.983696   \n",
       "179                  111        0.982919        0.980277        0.984766   \n",
       "180                   51        0.985070        0.980665        0.983696   \n",
       "181                  111        0.982919        0.980277        0.984766   \n",
       "182                   35        0.985147        0.980741        0.983772   \n",
       "183                  127        0.982843        0.980277        0.984690   \n",
       "184                   66        0.985070        0.980589        0.983619   \n",
       "185                  120        0.982919        0.980277        0.984690   \n",
       "186                   41        0.985070        0.980817        0.983696   \n",
       "187                  127        0.982843        0.980277        0.984690   \n",
       "188                   73        0.985070        0.980513        0.983543   \n",
       "189                  138        0.982919        0.980201        0.984613   \n",
       "190                   77        0.984993        0.980513        0.983543   \n",
       "191                  150        0.982919        0.980125        0.984613   \n",
       "192                   87        0.984993        0.980438        0.983467   \n",
       "193                  138        0.982919        0.980201        0.984613   \n",
       "194                   59        0.985223        0.980513        0.983619   \n",
       "195                  138        0.982919        0.980201        0.984613   \n",
       "196                   76        0.985147        0.980362        0.983543   \n",
       "197                  138        0.982919        0.980201        0.984613   \n",
       "198                   72        0.985147        0.980362        0.983619   \n",
       "199                  151        0.982919        0.980201        0.984536   \n",
       "\n",
       "     mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0        0.879083     0.004800           200  \n",
       "1        0.958969     0.002351           197  \n",
       "2        0.929591     0.002562           199  \n",
       "3        0.967939     0.001080           195  \n",
       "4        0.954387     0.000648           198  \n",
       "5        0.971742     0.000998           193  \n",
       "6        0.965205     0.001668           196  \n",
       "7        0.973870     0.000767           191  \n",
       "8        0.969672     0.001341           194  \n",
       "9        0.975261     0.000879           189  \n",
       "10       0.972203     0.000908           192  \n",
       "11       0.976318     0.001448           186  \n",
       "12       0.974263     0.000982           190  \n",
       "13       0.977355     0.001494           184  \n",
       "14       0.975443     0.001410           188  \n",
       "15       0.977999     0.001466           182  \n",
       "16       0.976285     0.001372           187  \n",
       "17       0.978353     0.001460           181  \n",
       "18       0.977263     0.000792           185  \n",
       "19       0.978531     0.001525           179  \n",
       "20       0.977883     0.001051           183  \n",
       "21       0.978866     0.001319           178  \n",
       "22       0.978396     0.001240           180  \n",
       "23       0.979649     0.001228           176  \n",
       "24       0.979040     0.001366           177  \n",
       "25       0.979961     0.001367           174  \n",
       "26       0.979710     0.001060           175  \n",
       "27       0.980322     0.001237           171  \n",
       "28       0.980020     0.000977           173  \n",
       "29       0.980474     0.001292           170  \n",
       "..            ...          ...           ...  \n",
       "170      0.983115     0.001733            18  \n",
       "171      0.982446     0.001680            85  \n",
       "172      0.983166     0.001785             7  \n",
       "173      0.982603     0.001836            55  \n",
       "174      0.983216     0.001699             3  \n",
       "175      0.982654     0.001842            49  \n",
       "176      0.983165     0.001664             8  \n",
       "177      0.982654     0.001842            49  \n",
       "178      0.983169     0.001867             6  \n",
       "179      0.982654     0.001842            49  \n",
       "180      0.983144     0.001840            13  \n",
       "181      0.982654     0.001842            49  \n",
       "182      0.983220     0.001840             2  \n",
       "183      0.982603     0.001809            56  \n",
       "184      0.983093     0.001867            22  \n",
       "185      0.982629     0.001813            54  \n",
       "186      0.983194     0.001772             4  \n",
       "187      0.982603     0.001809            56  \n",
       "188      0.983042     0.001894            29  \n",
       "189      0.982578     0.001817            62  \n",
       "190      0.983017     0.001866            33  \n",
       "191      0.982553     0.001850            68  \n",
       "192      0.982966     0.001893            42  \n",
       "193      0.982578     0.001817            62  \n",
       "194      0.983119     0.001955            17  \n",
       "195      0.982578     0.001817            62  \n",
       "196      0.983017     0.001988            32  \n",
       "197      0.982578     0.001817            62  \n",
       "198      0.983043     0.001995            28  \n",
       "199      0.982552     0.001789            69  \n",
       "\n",
       "[200 rows x 31 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs_df = pd.DataFrame(lr_gs_model.cv_results_)\n",
    "lr_gs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.430703</td>\n",
       "      <td>0.050437</td>\n",
       "      <td>0.022698</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>4.3</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 4.3, 'penalty': 'l1'}</td>\n",
       "      <td>0.983833</td>\n",
       "      <td>0.980678</td>\n",
       "      <td>0.982571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969464</td>\n",
       "      <td>0.968028</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98405</td>\n",
       "      <td>0.981027</td>\n",
       "      <td>0.982811</td>\n",
       "      <td>0.982629</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "84       0.430703      0.050437         0.022698        0.007199     4.3   \n",
       "\n",
       "   param_penalty                       params  split0_test_accuracy  \\\n",
       "84            l1  {'C': 4.3, 'penalty': 'l1'}              0.983833   \n",
       "\n",
       "    split1_test_accuracy  split2_test_accuracy  ...  split2_test_precision  \\\n",
       "84              0.980678              0.982571  ...               0.969464   \n",
       "\n",
       "    mean_test_precision  std_test_precision  rank_test_precision  \\\n",
       "84             0.968028            0.003165                    1   \n",
       "\n",
       "    split0_test_f1  split1_test_f1  split2_test_f1  mean_test_f1  std_test_f1  \\\n",
       "84         0.98405        0.981027        0.982811      0.982629     0.001241   \n",
       "\n",
       "    rank_test_f1  \n",
       "84            53  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs_df[lr_gs_df.rank_test_precision == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#want to reduce number of records predicted as 0 that are actually 1 \n",
    "seaborn_confusion_matrix(y_val, lr_y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2b725ba8>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(y_val, lr_y_val_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 0.9569808369182636\n",
      "Adjusted Precision: 0.8797814207650273\n",
      "Adjusted Recall: 0.44846796657381616\n",
      "Adjusted F1 Score: 0.5940959409594097\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_pred_adj, cm = adjust_threshold_and_score(y_val, lr_y_val_prob, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lr_pred_adj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_df['adjusted class'] = lr_pred_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob 0</th>\n",
       "      <th>prob 1</th>\n",
       "      <th>predicted class</th>\n",
       "      <th>actual class</th>\n",
       "      <th>adjusted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9203</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17380</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob 0  prob 1  predicted class  actual class  adjusted_class\n",
       "17498    0.73    0.27                0             0               0\n",
       "9203     1.00    0.00                0             0               0\n",
       "17380    0.99    0.01                0             0               0\n",
       "25176    1.00    0.00                0             0               0\n",
       "3828     1.00    0.00                0             0               0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob 0</th>\n",
       "      <th>prob 1</th>\n",
       "      <th>predicted class</th>\n",
       "      <th>actual class</th>\n",
       "      <th>adjusted class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23876</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28669</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14414</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob 0  prob 1  predicted class  actual class  adjusted class\n",
       "12608    0.94    0.06                0             1               0\n",
       "23876    0.45    0.55                1             0               0\n",
       "28669    0.75    0.25                0             1               0\n",
       "14414    0.49    0.51                1             0               0\n",
       "2748     0.72    0.28                0             1               0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_misclassified_df = lr_pred_df[lr_pred_df['predicted class'] != lr_pred_df['actual class']]\n",
    "lr_misclassified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 5)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_misclassified_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob 0</th>\n",
       "      <th>prob 1</th>\n",
       "      <th>predicted class</th>\n",
       "      <th>actual class</th>\n",
       "      <th>adjusted class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28669</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13596</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob 0  prob 1  predicted class  actual class  adjusted class\n",
       "12608    0.94    0.06                0             1               0\n",
       "28669    0.75    0.25                0             1               0\n",
       "2748     0.72    0.28                0             1               0\n",
       "8202     0.89    0.11                0             1               0\n",
       "13596    0.61    0.39                0             1               0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_misclassified2_df = lr_misclassified_df[lr_misclassified_df['adjusted class'] != lr_misclassified_df['actual class']]\n",
    "lr_misclassified2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_misclassified2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a reson why so many muslims might be'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[12608]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nazi swastika ebay trump donaldtrump republicwhitepower'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lem_tweet[28669]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ever notice how much scum #trump hires ?'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet[2748]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Final Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model_countvect =  count_vect.fit_transform(X_model.lem_tweet)\n",
    "X_test_countvect =  count_vect.transform(X_test.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(penalty = 'l1', C = 2.5, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=10, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_model_countvect, y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_pred_test = log.predict(X_test_countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_prob_test = log.predict_proba(X_test_countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5 import explain_weights, explain_prediction\n",
    "from eli5.formatters import format_as_html, format_as_text, format_html_styles, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.915\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        allahsoil\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.658\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        malevote\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.550\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        discrimination\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.500\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        canucks\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.374\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        latent\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.065\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wew\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.037\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        biblical\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.903\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        happyholidays\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.14%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.871\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        gu\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.827\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        klan\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.823\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        evolution\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.797\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        shallow\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.752\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sikh\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.722\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        scurvy\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.719\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        jews\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.707\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        blacklivesmatter\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.671\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        lede\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.655\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        islamophobia\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.615\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        systemic\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.57%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1371 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.90%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 756 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.017\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mommas\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(log, vec= count_vect, target_names= y_test, horizontal_layout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-871b379ca551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mexpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mshow_html_expl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    825\u001b[0m                             '1 positional argument')\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/sklearn/explain_prediction.py\u001b[0m in \u001b[0;36mexplain_prediction_linear_classifier\u001b[0;34m(clf, doc, vec, top, top_targets, target_names, targets, feature_names, feature_re, feature_filter, vectorized)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     \u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/sklearn/utils.py\u001b[0m in \u001b[0;36mget_X\u001b[0;34m(doc, vec, vectorized, to_dense)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_dense\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                                tokenize)\n\u001b[1;32m    351\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 352\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "for doc in y_test[:10]:\n",
    "    expl = explain_prediction(log, doc, vec = count_vect, target_names = y_test, top_targets=1)\n",
    "    show_html_expl(expl, force_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a282d5940>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# skplt.metrics.plot_precision_recall_curve(y_test, lr_y_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>5885</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>180</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0         5885           60\n",
       "actual 1          180          268"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_confusion_matrix(y_test, lr_y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Accuracy: 0.9580791490692946\n",
      "Adjusted Precision: 0.6890756302521008\n",
      "Adjusted Recall: 0.7321428571428571\n",
      "Adjusted F1 Score: 0.7099567099567099\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adjust_threshold_and_score(y_test, lr_y_prob_test, .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.93              0.93             0.93   \n",
       "Train F1                          0.00              0.00             0.00   \n",
       "Train Precision                   0.00              0.00             0.00   \n",
       "Train Recall                      0.00              0.00             0.00   \n",
       "Validation Accuracy               0.93              0.93             0.93   \n",
       "Validation F1                     0.00              0.00             0.00   \n",
       "Validation Precision              0.00              0.00             0.00   \n",
       "Validation Recall                 0.00              0.00             0.00   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.93  \n",
       "Train F1                         0.00  \n",
       "Train Precision                  0.00  \n",
       "Train Recall                     0.00  \n",
       "Validation Accuracy              0.93  \n",
       "Validation F1                    0.00  \n",
       "Validation Precision             0.00  \n",
       "Validation Recall                0.00  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results1 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            SVC(gamma='auto', probability = True, random_state = 10), \n",
    "                            vectorization_list)\n",
    "svm_results1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_results1.to_csv('data/SVM_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.07              0.07             0.07   \n",
       "Train F1                          0.13              0.13             0.13   \n",
       "Train Precision                   0.07              0.07             0.07   \n",
       "Train Recall                      1.00              1.00             1.00   \n",
       "Validation Accuracy               0.07              0.07             0.07   \n",
       "Validation F1                     0.13              0.13             0.13   \n",
       "Validation Precision              0.07              0.07             0.07   \n",
       "Validation Recall                 1.00              1.00             1.00   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.08  \n",
       "Train F1                         0.13  \n",
       "Train Precision                  0.07  \n",
       "Train Recall                     1.00  \n",
       "Validation Accuracy              0.08  \n",
       "Validation F1                    0.13  \n",
       "Validation Precision             0.07  \n",
       "Validation Recall                1.00  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results2 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            SVC(gamma='auto', class_weight = 'balanced', probability = True, random_state = 10), \n",
    "                            vectorization_list)\n",
    "svm_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_results2.to_csv('data/SVM_results.csv', mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7e8ee2faa6b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlem_tweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                             vectorization_list, sampling = 'upsample')\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msvm_results3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b79f7d9d1dad>\u001b[0m in \u001b[0;36mwrapper_compare_vectorizations\u001b[0;34m(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list, sampling, sample_class)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'upsample'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample_compare_vectorization_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorization_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'downsample'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b52dae20cba0>\u001b[0m in \u001b[0;36mupsample_compare_vectorization_model\u001b[0;34m(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#train and validate classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my_train_up_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_up_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my_train_up_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_up_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \"\"\"\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_sparse_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_support_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             self.probA_, self.probB_)\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# svm_results3 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "#                             y_train, X_val.lem_tweet, y_val, \n",
    "#                             SVC(gamma='auto', random_state = 10), \n",
    "#                             vectorization_list, sampling = 'upsample')\n",
    "# svm_results3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.51              0.84             0.80   \n",
       "Train F1                          0.67              0.85             0.76   \n",
       "Train Precision                   0.51              0.80             0.94   \n",
       "Train Recall                      1.00              0.91             0.63   \n",
       "Validation Accuracy               0.10              0.74             0.89   \n",
       "Validation F1                     0.13              0.32             0.45   \n",
       "Validation Precision              0.07              0.20             0.35   \n",
       "Validation Recall                 1.00              0.89             0.60   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.54  \n",
       "Train F1                         0.14  \n",
       "Train Precision                  0.99  \n",
       "Train Recall                     0.08  \n",
       "Validation Accuracy              0.93  \n",
       "Validation F1                    0.13  \n",
       "Validation Precision             1.00  \n",
       "Validation Recall                0.07  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results4 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            SVC(gamma= 'auto', probability = True, random_state = 10), \n",
    "                            vectorization_list, sampling = 'downsample')\n",
    "svm_results4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_results5 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "#                             y_train, X_val.lem_tweet, y_val, \n",
    "#                             SVC(gamma='auto', probability = True, random_state = 10), \n",
    "#                             vectorization_list, sampling = 'smote')\n",
    "# svm_results5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Searching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfid2 =  tfidf_ngram2.fit_transform(X_train.lemmatized_tweet)\n",
    "X_val_tfid2 =  tfidf_ngram2.transform(X_val.lemmatized_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC\n",
    "\n",
    "params = {\n",
    "'C': [0.1,.2, .5, 0.8, 1, 1.5, 2.0, 3.0, 4.0, 5.0],\n",
    "'kernel':['linear', 'rbf'],\n",
    "'gamma' :[0.1,0.8,1,1.2,1.4],\n",
    "'class_weight': [{0:5, 1:5}, {0:2, 1:8}, {0:4, 1:6}, {0:8, 1:2}]}\n",
    "\n",
    "scores = ['accuracy','recall','precision','f1']\n",
    "\n",
    "scv_rs = RandomizedSearchCV(rfc, param_distributions = parameters, scoring = scores, cv = 3, refit = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rs.fit(X_train_tfid2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multiple Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " RandomForestClassifier(max_depth= 20, \n",
    "                                   n_estimators = 100, class_weight='balanced', random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.99             0.99   \n",
       "Train F1                          0.95              0.94             0.94   \n",
       "Train Precision                   1.00              1.00             1.00   \n",
       "Train Recall                      0.91              0.89             0.89   \n",
       "Validation Accuracy               0.96              0.95             0.96   \n",
       "Validation F1                     0.61              0.55             0.58   \n",
       "Validation Precision              0.93              0.84             0.86   \n",
       "Validation Recall                 0.45              0.41             0.44   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.95  \n",
       "Train F1                         0.41  \n",
       "Train Precision                  0.92  \n",
       "Train Recall                     0.26  \n",
       "Validation Accuracy              0.93  \n",
       "Validation F1                    0.20  \n",
       "Validation Precision             0.64  \n",
       "Validation Recall                0.12  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing; no hyperparameter tuning\n",
    "rfc_results1 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), vectorization_list)\n",
    "rfc_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_results1.to_csv('data/RFC_results.csv',mode = 'a',header ='column_names')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.99             0.99   \n",
       "Train F1                          0.95              0.94             0.94   \n",
       "Train Precision                   1.00              0.98             0.98   \n",
       "Train Recall                      0.91              0.90             0.91   \n",
       "Validation Accuracy               0.96              0.95             0.95   \n",
       "Validation F1                     0.54              0.54             0.55   \n",
       "Validation Precision              0.98              0.84             0.84   \n",
       "Validation Recall                 0.37              0.40             0.41   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.61  \n",
       "Train F1                         0.25  \n",
       "Train Precision                  0.14  \n",
       "Train Recall                     0.91  \n",
       "Validation Accuracy              0.60  \n",
       "Validation F1                    0.21  \n",
       "Validation Precision             0.12  \n",
       "Validation Recall                0.77  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and class weights balanced\n",
    "rfc_results2 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10, class_weight = 'balanced'), \n",
    "                            vectorization_list)\n",
    "rfc_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_results2.to_csv('data/RFC_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    1.00              1.00             1.00   \n",
       "Train F1                          1.00              1.00             1.00   \n",
       "Train Precision                   1.00              1.00             1.00   \n",
       "Train Recall                      1.00              1.00             1.00   \n",
       "Validation Accuracy               0.96              0.95             0.95   \n",
       "Validation F1                     0.59              0.61             0.59   \n",
       "Validation Precision              0.93              0.75             0.77   \n",
       "Validation Recall                 0.43              0.52             0.48   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.85  \n",
       "Train F1                         0.83  \n",
       "Train Precision                  0.94  \n",
       "Train Recall                     0.75  \n",
       "Validation Accuracy              0.90  \n",
       "Validation F1                    0.38  \n",
       "Validation Precision             0.33  \n",
       "Validation Recall                0.43  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and upsampling\n",
    "rfc_results3 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), \n",
    "                            vectorization_list, sampling = 'upsample')\n",
    "rfc_results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_results3.to_csv('data/RFC_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              0.99             0.99   \n",
       "Train F1                          0.99              0.99             0.99   \n",
       "Train Precision                   1.00              1.00             1.00   \n",
       "Train Recall                      0.98              0.98             0.98   \n",
       "Validation Accuracy               0.86              0.84             0.83   \n",
       "Validation F1                     0.42              0.39             0.38   \n",
       "Validation Precision              0.30              0.27             0.26   \n",
       "Validation Recall                 0.73              0.74             0.74   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.87  \n",
       "Train F1                         0.85  \n",
       "Train Precision                  0.97  \n",
       "Train Recall                     0.76  \n",
       "Validation Accuracy              0.80  \n",
       "Validation F1                    0.26  \n",
       "Validation Precision             0.18  \n",
       "Validation Recall                0.50  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and downsampling\n",
    "rfc_results4 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), \n",
    "                            vectorization_list, sampling = 'downsample')\n",
    "rfc_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_results4.to_csv('data/RFC_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_VECTORIZER</th>\n",
       "      <th>TFIDF_VECTORIZER</th>\n",
       "      <th>TFIDF_NGRAM_1_2</th>\n",
       "      <th>TFIDF_NGRAM_2_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Precision</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Recall</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      COUNT_VECTORIZER  TFIDF_VECTORIZER  TFIDF_NGRAM_1_2  \\\n",
       "Train Accuracy                    0.99              1.00             1.00   \n",
       "Train F1                          0.96              0.99             0.99   \n",
       "Train Precision                   0.95              0.98             0.99   \n",
       "Train Recall                      0.96              0.99             0.99   \n",
       "Validation Accuracy               0.89              0.93             0.94   \n",
       "Validation F1                     0.42              0.51             0.53   \n",
       "Validation Precision              0.34              0.52             0.56   \n",
       "Validation Recall                 0.55              0.50             0.50   \n",
       "\n",
       "                      TFIDF_NGRAM_2_3  \n",
       "Train Accuracy                   0.64  \n",
       "Train F1                         0.25  \n",
       "Train Precision                  0.15  \n",
       "Train Recall                     0.86  \n",
       "Validation Accuracy              0.59  \n",
       "Validation F1                    0.20  \n",
       "Validation Precision             0.12  \n",
       "Validation Recall                0.72  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest: compare vectorizers with lemmatizing and smote\n",
    "rfc_results5 = wrapper_compare_vectorizations(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(random_state=10), \n",
    "                            vectorization_list, sampling = 'smote', sample_class = 'not majority')\n",
    "rfc_results5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_results5.to_csv('data/RFC_results.csv',mode = 'a',header ='column_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Searching For Best Fit for Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_countvect =  count_vect.fit_transform(X_train.lem_tweet)\n",
    "X_val_countvect =  count_vect.transform(X_val.lem_tweet)\n",
    "# X_test_countvect = count_vect.transform(X_test.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# parameters = {'n_estimators' : [40, 60, 80, 100, 120, 150],\n",
    "# 'max_leaf_nodes' : [100, 200, 400, 600],\n",
    "# 'random_state' : [10],\n",
    "# 'max_depth': [5, 7, 10, 20, 30],\n",
    "#  'verbose' : [0],\n",
    "# 'class_weight': [{0:5, 1:5}, {0:2, 1:8}, {0:4, 1:6}, {0:8, 1:2}] }\n",
    "# # 'class_weight': ['balanced', 'balanced_subsample']}\n",
    "          \n",
    "# rfc_gs = GridSearchCV(rfc, param_grid=parameters, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "np.random.seed(10)\n",
    "rfc = RandomForestClassifier(random_state=10)\n",
    "\n",
    "parameters = {'n_estimators' : [40, 60, 80, 100, 120],\n",
    "'max_leaf_nodes' : [100, 200, 300, 400],\n",
    "'random_state' : [10],\n",
    "'max_depth': [5, 6, 7, 8, 10, 20, 25, 30],\n",
    " 'verbose' : [0],\n",
    "# 'class_weight': [{0:5, 1:5}, {0:2, 1:8}, {0:4, 1:6}, {0:6, 1: 4}, {0:8, 1:2}]}\n",
    "'class_weight': ['balanced', 'balanced_subsample']}\n",
    "\n",
    "scores = ['accuracy','recall','precision','f1']\n",
    "\n",
    "rfc_gs = RandomizedSearchCV(rfc, param_distributions = parameters, scoring = scores, cv = 3, refit = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'class_weight': ['balanced',\n",
       "                                                         'balanced_subsample'],\n",
       "                                        'max_depth': [5, 6, 7, 8, 10, 20, 25,\n",
       "                                                      30],\n",
       "                                        'max_leaf_nodes': [100, 200, 300, 400],\n",
       "                                        'n_estimators': [40, 60, 80, 100, 120],\n",
       "                                        'random_state': [10], 'verbose': [0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit='f1',\n",
       "                   return_train_score=False,\n",
       "                   scoring=['accuracy', 'recall', 'precision', 'f1'],\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_gs.fit(X_train_countvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 0,\n",
       " 'random_state': 10,\n",
       " 'n_estimators': 80,\n",
       " 'max_leaf_nodes': 200,\n",
       " 'max_depth': 25,\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800459005990697"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_verbose</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.175946</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.258776</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575281</td>\n",
       "      <td>0.550092</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>4</td>\n",
       "      <td>0.578629</td>\n",
       "      <td>0.550244</td>\n",
       "      <td>0.554713</td>\n",
       "      <td>0.561196</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.066260</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.131001</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380244</td>\n",
       "      <td>0.391458</td>\n",
       "      <td>0.058942</td>\n",
       "      <td>9</td>\n",
       "      <td>0.516854</td>\n",
       "      <td>0.417417</td>\n",
       "      <td>0.461791</td>\n",
       "      <td>0.465357</td>\n",
       "      <td>0.040673</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.248075</td>\n",
       "      <td>0.041720</td>\n",
       "      <td>0.380508</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614428</td>\n",
       "      <td>0.612758</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607341</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.561364</td>\n",
       "      <td>0.580046</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.644353</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.309183</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458466</td>\n",
       "      <td>0.447967</td>\n",
       "      <td>0.032899</td>\n",
       "      <td>6</td>\n",
       "      <td>0.539945</td>\n",
       "      <td>0.493084</td>\n",
       "      <td>0.519928</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>0.019199</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.503034</td>\n",
       "      <td>0.019810</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>300</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.399490</td>\n",
       "      <td>0.037573</td>\n",
       "      <td>8</td>\n",
       "      <td>0.520354</td>\n",
       "      <td>0.465608</td>\n",
       "      <td>0.474603</td>\n",
       "      <td>0.486857</td>\n",
       "      <td>0.023971</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.821604</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.185996</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361675</td>\n",
       "      <td>0.362493</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>10</td>\n",
       "      <td>0.462913</td>\n",
       "      <td>0.419448</td>\n",
       "      <td>0.450237</td>\n",
       "      <td>0.444201</td>\n",
       "      <td>0.018251</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.243501</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.534973</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.669043</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596698</td>\n",
       "      <td>0.574096</td>\n",
       "      <td>0.566586</td>\n",
       "      <td>0.579127</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.928581</td>\n",
       "      <td>0.024586</td>\n",
       "      <td>0.359931</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385604</td>\n",
       "      <td>0.423771</td>\n",
       "      <td>0.052060</td>\n",
       "      <td>7</td>\n",
       "      <td>0.540952</td>\n",
       "      <td>0.483412</td>\n",
       "      <td>0.477707</td>\n",
       "      <td>0.500693</td>\n",
       "      <td>0.028565</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.314601</td>\n",
       "      <td>0.029668</td>\n",
       "      <td>0.367406</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>0.563284</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>3</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.574850</td>\n",
       "      <td>0.556745</td>\n",
       "      <td>0.575199</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.386453</td>\n",
       "      <td>0.175902</td>\n",
       "      <td>0.196988</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499037</td>\n",
       "      <td>0.508564</td>\n",
       "      <td>0.026655</td>\n",
       "      <td>5</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.526116</td>\n",
       "      <td>0.519559</td>\n",
       "      <td>0.534274</td>\n",
       "      <td>0.016392</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_verbose  \\\n",
       "0       3.175946      0.028908         0.258776        0.000477             0   \n",
       "1       1.066260      0.011570         0.131001        0.000324             0   \n",
       "2       5.248075      0.041720         0.380508        0.002024             0   \n",
       "3       2.644353      0.005158         0.309183        0.004145             0   \n",
       "4       1.503034      0.019810         0.244510        0.001119             0   \n",
       "5       0.821604      0.001232         0.185996        0.001016             0   \n",
       "6       8.243501      0.022627         0.534973        0.021809             0   \n",
       "7       1.928581      0.024586         0.359931        0.001668             0   \n",
       "8       5.314601      0.029668         0.367406        0.000181             0   \n",
       "9       2.386453      0.175902         0.196988        0.019729             0   \n",
       "\n",
       "  param_random_state param_n_estimators param_max_leaf_nodes param_max_depth  \\\n",
       "0                 10                 60                  300              20   \n",
       "1                 10                 40                  100              10   \n",
       "2                 10                 80                  200              25   \n",
       "3                 10                100                  400              10   \n",
       "4                 10                 80                  300               7   \n",
       "5                 10                 60                  100               5   \n",
       "6                 10                100                  300              30   \n",
       "7                 10                120                  300               6   \n",
       "8                 10                 80                  100              25   \n",
       "9                 10                 40                  200              20   \n",
       "\n",
       "   param_class_weight  ... split2_test_precision  mean_test_precision  \\\n",
       "0            balanced  ...              0.575281             0.550092   \n",
       "1            balanced  ...              0.380244             0.391458   \n",
       "2            balanced  ...              0.614428             0.612758   \n",
       "3            balanced  ...              0.458466             0.447967   \n",
       "4            balanced  ...              0.382353             0.399490   \n",
       "5            balanced  ...              0.361675             0.362493   \n",
       "6  balanced_subsample  ...              0.672414             0.669043   \n",
       "7            balanced  ...              0.385604             0.423771   \n",
       "8  balanced_subsample  ...              0.570175             0.563284   \n",
       "9            balanced  ...              0.499037             0.508564   \n",
       "\n",
       "   std_test_precision  rank_test_precision  split0_test_f1  split1_test_f1  \\\n",
       "0            0.025271                    4        0.578629        0.550244   \n",
       "1            0.058942                    9        0.516854        0.417417   \n",
       "2            0.031115                    2        0.607341        0.571429   \n",
       "3            0.032899                    6        0.539945        0.493084   \n",
       "4            0.037573                    8        0.520354        0.465608   \n",
       "5            0.034125                   10        0.462913        0.419448   \n",
       "6            0.015115                    1        0.596698        0.574096   \n",
       "7            0.052060                    7        0.540952        0.483412   \n",
       "8            0.009663                    3        0.594000        0.574850   \n",
       "9            0.026655                    5        0.557143        0.526116   \n",
       "\n",
       "   split2_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "0        0.554713      0.561196     0.012462             4  \n",
       "1        0.461791      0.465357     0.040673             9  \n",
       "2        0.561364      0.580046     0.019735             1  \n",
       "3        0.519928      0.517653     0.019199             6  \n",
       "4        0.474603      0.486857     0.023971             8  \n",
       "5        0.450237      0.444201     0.018251            10  \n",
       "6        0.566586      0.579127     0.012798             2  \n",
       "7        0.477707      0.500693     0.028565             7  \n",
       "8        0.556745      0.575199     0.015211             3  \n",
       "9        0.519559      0.534274     0.016392             5  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_df = pd.DataFrame(rfc_gs.cv_results_)\n",
    "rfc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_verbose</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.243501</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.534973</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.669043</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596698</td>\n",
       "      <td>0.574096</td>\n",
       "      <td>0.566586</td>\n",
       "      <td>0.579127</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_verbose  \\\n",
       "6       8.243501      0.022627         0.534973        0.021809             0   \n",
       "\n",
       "  param_random_state param_n_estimators param_max_leaf_nodes param_max_depth  \\\n",
       "6                 10                100                  300              30   \n",
       "\n",
       "   param_class_weight  ... split2_test_precision  mean_test_precision  \\\n",
       "6  balanced_subsample  ...              0.672414             0.669043   \n",
       "\n",
       "   std_test_precision  rank_test_precision  split0_test_f1  split1_test_f1  \\\n",
       "6            0.015115                    1        0.596698        0.574096   \n",
       "\n",
       "   split2_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n",
       "6        0.566586      0.579127     0.012798             2  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_df[rfc_df.rank_test_precision==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(n_estimators = 80, max_leaf_nodes = 200, class_weight='balanced',\n",
    "                            max_depth = 25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=25, max_features='auto',\n",
       "                       max_leaf_nodes=200, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=80, n_jobs=None, oob_score=False,\n",
       "                       random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc2.fit(X_train_countvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rfc2_pred = rfc2.predict(X_train_countvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7455936148985699"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_train, y_rfc2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_X_train, rfc_X_val, rfc_y_train_pred, rfc_y_val_pred, rfc_y_val_prob, rfc_metrics, rfc_pred_df = \\\n",
    "\\\n",
    "wrapper_single_vectorization(X_train.lem_tweet, \n",
    "                            y_train, X_val.lem_tweet, y_val, \n",
    "                            RandomForestClassifier(n_estimators = 80, max_leaf_nodes = 200, \n",
    "                            class_weight = 'balanced', max_depth = 25, random_state=10), \n",
    "                            count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not hate       0.97      0.96      0.97      4755\n",
      " hate speech       0.54      0.62      0.58       359\n",
      "\n",
      "    accuracy                           0.94      5114\n",
      "   macro avg       0.75      0.79      0.77      5114\n",
      "weighted avg       0.94      0.94      0.94      5114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(y_val, rfc_y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>4561</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>135</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted 0  predicted 1\n",
       "actual 0         4561          194\n",
       "actual 1          135          224"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print confusion matrix    \n",
    "pd.DataFrame(confusion_matrix(y_val, rfc_y_val_pred), index = ['actual 0','actual 1'], columns = ['predicted 0', 'predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48749982, 0.51250018],\n",
       "       [0.5645008 , 0.4354992 ],\n",
       "       [0.53219262, 0.46780738],\n",
       "       ...,\n",
       "       [0.61720324, 0.38279676],\n",
       "       [0.57013572, 0.42986428],\n",
       "       [0.55695865, 0.44304135]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_y_val_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob 0</th>\n",
       "      <th>prob 1</th>\n",
       "      <th>predicted class</th>\n",
       "      <th>actual class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9203</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17380</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob 0  prob 1  predicted class  actual class\n",
       "17498    0.49    0.51                1             0\n",
       "9203     0.56    0.44                0             0\n",
       "17380    0.53    0.47                0             0\n",
       "25176    0.60    0.40                0             0\n",
       "3828     0.66    0.34                0             0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# def plot_feature_importances(rfc2):\n",
    "#     n_features = X_val_countvect.shape[1]\n",
    "#     plt.figure(figsize=(8,8))\n",
    "#     plt.barh(range(n_features), rfc2.feature_importances_, align='center') \n",
    "#     plt.yticks(np.arange(n_features), countvect.values) \n",
    "#     plt.xlabel(\"Feature importance\")\n",
    "#     plt.ylabel(\"Feature\")\n",
    "\n",
    "# plot_feature_importances(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_feature_importances(model):\n",
    "    n_features = x_train_sc.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), x_train_sc.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "plot_feature_importances(rfc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-train pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20455,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.tokenized_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token_list = list(X_train.tokenized_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token_sumlist = sum(X_train_token_list,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique number of words in the training dataset is: 28682\n"
     ]
    }
   ],
   "source": [
    "X_train_unique_tokens = set(X_train_token_sumlist)\n",
    "print('The unique number of words in the training dataset is: {}'.format(len(X_train_unique_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X-val pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique number of words in the validation dataset is: 11761\n"
     ]
    }
   ],
   "source": [
    "X_val_token_list = list(X_val['tokenized_tweet'])\n",
    "X_val_token_sumlist = sum(X_val_token_list,[])\n",
    "X_val_unique_tokens = set(X_val_token_sumlist)\n",
    "\n",
    "print('The unique number of words in the validation dataset is: {}'.format(len(X_val_unique_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X-test pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique number of words in the training dataset is: 13677\n"
     ]
    }
   ],
   "source": [
    "X_test_token_list = list(X_test['tokenized_tweet'])\n",
    "X_test_token_sumlist = sum(X_test_token_list,[])\n",
    "\n",
    "X_test_unique_tokens = set(X_test_token_sumlist)\n",
    "print('The unique number of words in the training dataset is: {}'.format(len(X_test_unique_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(X_train_token_list, sg=1, min_count=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.train(X_train_token_list, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('data/w2v.model')\n",
    "\n",
    "w2v = gensim.models.Word2Vec.load('data/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec.load('data/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20455"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vocab= w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w2v_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv['trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(['trump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(['racist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.most_similar(positive=['lazy','black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.get_keras_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_X = w2v.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = X_train_token_list[1]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create average vector for train and test from model\n",
    "#returned list of numpy arrays are then stacked \n",
    "\n",
    "X_train_w2v = np.concatenate([avg_word_vectors(word, w2v) for word in X_train_token_list])\n",
    "\n",
    "X_val_w2v = np.concatenate([avg_word_vectors(word, w2v) for word in X_val_token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_2[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train Accuracy': 0.84,\n",
       " 'Train Precision': 0.29,\n",
       " 'Train Recall': 0.85,\n",
       " 'Train F1': 0.43,\n",
       " 'Validation Accuracy': 0.84,\n",
       " 'Validation Precision': 0.28,\n",
       " 'Validation Recall': 0.86,\n",
       " 'Validation F1': 0.43}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_w2v_model(X_train_w2v, y_train, X_val_w2v, y_val, LogisticRegression(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train Accuracy': 1.0,\n",
       " 'Train Precision': 0.99,\n",
       " 'Train Recall': 1.0,\n",
       " 'Train F1': 0.99,\n",
       " 'Validation Accuracy': 0.93,\n",
       " 'Validation Precision': 0.51,\n",
       " 'Validation Recall': 0.58,\n",
       " 'Validation F1': 0.54}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_w2v_model(X_train_w2v_2, y_train, X_val_w2v_2, y_val, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# glove_input_file = 'data/glove.twitter.27B.100d.txt'\n",
    "# glove_output_file = 'data/glove.txt.word2vec'\n",
    "# glove2word2vec(glove_input_file, glove_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format('data/glove.txt.word2vec', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model.most_similar('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_glove2 = np.empty((20455, 100))\n",
    "# for sentence in X_train_token_list:\n",
    "#     np.append(X_train_glove2, np.mean([glove_model[w] for w in sentence if w in glove_model]\n",
    "#                    or [np.zeros(100)], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove = np.concatenate([avg_word_vectors(w, glove_model) for w in X_train_token_list])\n",
    "X_val_glove = np.concatenate([avg_word_vectors(w, glove_model) for w in X_val_token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove[255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train Accuracy': 0.88,\n",
       " 'Train Precision': 0.03,\n",
       " 'Train Recall': 0.02,\n",
       " 'Train F1': 0.02,\n",
       " 'Validation Accuracy': 0.88,\n",
       " 'Validation Precision': 0.03,\n",
       " 'Validation Recall': 0.03,\n",
       " 'Validation F1': 0.03}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_w2v_model (X_train_glove, y_train, X_val_glove, y_val, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Testing Scraped Trump Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trump_df= pd.read_csv('data/cleaned-trump-tweet.csv')\n",
    "trump_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_countvect =  count_vect.fit_transform(X_train_up.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train_countvect, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump = count_vect.transform(trump_df.lem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump = X_trump.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trump.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict = logreg.predict(X_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['predictions'] = y_trump_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict_prob = logreg.predict_proba(X_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trump_predict_prob = pd.DataFrame(y_trump_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df['predict_probability'] = y_trump_predict_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df = trump_df[['tweet','predictions', 'predict_probability']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump0 = trump_df[trump_df.predictions == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump0.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df[trump_df.predictions == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump1 = trump_df[trump_df.predictions == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump1.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
